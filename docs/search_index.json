[["index.html", "Model Your World: Introduction to Modeling and Simulation Chapter 1 Welcome 1.1 Teaching Team Introductions Gaj Sivandran 1.2 Course Highlights 1.3 What are the learning outcomes 1.4 Notes and Textbooks 1.5 Course Topics 1.6 Classroom Etiquette 1.7 Assessment", " Model Your World: Introduction to Modeling and Simulation Gaj Sivandran 2025-10-01 Chapter 1 Welcome 1.1 Teaching Team Introductions Gaj Sivandran Teaching Interests Design (freshman and senior) Fundamental engineering (statics, fluids) Environmental labs Water resources Research Interests Climate change Active learning pedagogy Simulation modeling Decision support (socio-economic modelling) Random Facts I have an 11yr old daughter that helps me write exam questions Dogs &gt;Cats, Cricket &gt; Baseball, AFL &gt; NFL, Vegemite &gt; Peanut butter I like to run very very long distances, stilling working on why 1.2 Course Highlights This is the first offering of this course - what does that mean? I’m looking for your continuous feedback on what is working and what is not I’m going apply “Just-In-Time” teaching philosophy. What this essentially means is the course material is dynamic, if there is a need from the class to cover a topic - we can add it in Accessibility requirements for the Spring. 1.3 What are the learning outcomes By the end of the course, students will be able to: Explain the philosophy of modeling: abstraction, assumptions, and trade-offs. Use AI tools responsibly to support model design, coding, and analysis. Build and analyze basic mathematical and computational models (e.g., growth, predator–prey, carbon cycles). Implement simulation techniques in R, including discrete-event, continuous-time, and agent-based models. Explore the roles of uncertainty, sensitivity, and validation in modeling. Communicate modeling results clearly through visualizations, reports, and presentations. Class Discussion Anything you want to add/remove/emphasize/de-emphasize? Class Discussion Lets find out why you all have decided to be here. With the people around you, discuss why you are taking this class. We’ll share back in 5mins. Class Discussion The way we code is changing rapidly right now with the development of LLMs. You might rightly ask “why do we need to know how to code?” Discuss it with the people at your table We are scientists! So it would be great to see arguments from all perspectives - play ‘devil’s advocate’ its more fun if we don’t all agree What should our goal be in light of your discussion? One of my favorite education quotes: “We are currently preparing students for jobs that don’t yet exist… using technologies that haven’t been invented… in order to solve problems we don’t even know are problems yet” - Richard Riley U.S. Secretary of Education (1993-2001) 1.4 Notes and Textbooks Quick Canvas tour I am writing and publishing the textbook on the fly. To make sure you are working with the most up-to-date version hit refresh or close the tab from time to time. 1.5 Course Topics This being the first year – this is my ambitious list of topics – we’ll see how far we get (maybe further) Introduction to Modeling – abstraction, assumptions, model types. AI &amp; Modeling Tools – using LLMs to support coding and model design. Mathematical Models – parameters, functions, growth models. Difference Equations – discrete-time dynamics, feedback, stability. Differential Equations – continuous-time systems in ecology/environment. Simulation as a Tool – discrete-event and continuous-time simulation. Uncertainty &amp; Sensitivity – calibration, robustness, validation. Spatial &amp; Agent-Based Models – individuals and space in systems. Communicating Models – visualization, ethics, limits. Capstone Showcase – final project presentations. Class Discussion Anything you want to add/remove/emphasize/de-emphasize? 1.6 Classroom Etiquette Please feel free to bring your breakfast/lunch to class – just be sure to clean up before you leave Bring whatever tech you need to take notes and engage. We will code in class so setting up R Studio is a good idea Ask questions – but please be respectful of all voices and views - wrong answers have more value than right ones! Norms - Class Discussion Lets come up with a set of rules and expectations for this class and then lets agree to follow them. 1.7 Assessment My goal with the assessments is to encourage you to put energy in the right places. I do not want to create busy work in this class. But - At the same time - sometimes having a due date forces us to do the things that are good for us, but not as much fun. Class Discussion Right now the assessment breakdown is: Homework &amp; Labs (40%) – Weekly assignments and lab reports where students build, test, and reflect on models. Final Project (40%) – Develop and present a model of a real-world environmental system (individual or group). Includes a written report and in-class presentation. Participation &amp; Preparation (20%) – In-class activities, peer feedback, and engagement in discussions. What should the project be worth? Here are the basics Milestone 1: Proposal &amp; Scoping (Week 3) Topic idea (1–2 paragraphs) Research question(s) Initial model concept (sketch or description) Deliverable: 1–2 page written proposal + brief in-class discussion Milestone 2: Background &amp; Model Design (Week 5) Short background review (1–2 pages, with at least 3–5 references) Model framework (diagram of variables, flows, assumptions) Plan for methods (what kind of model and why) Deliverable: Background report + 3–5 minute pitch with peer Q&amp;A Milestone 3: Prototype Model (Week 7) First working version of your model in R At least one test run with outputs 1-page reflection on challenges and next steps Deliverable: Code + reflection memo Milestone 4: Model Refinement &amp; Analysis (Week 9) Improved and more complete model Sensitivity tests, scenario comparisons, or uncertainty analysis At least 2–3 polished visualizations Deliverable: Draft results section (1–2 pages) with figures Milestone 5: Final Report &amp; Showcase (Week 10) Final written report (6–8 pages, including intro, methods, results, discussion, references, and code appendix) A poster of your work – we’ll have our own digital poster session at the end of this course. Deliverable: Report + poster presentation Grading Detailed rubrics will be provided for each milestone. For Milestones 1 through 4, you will be given the opportunity to address feedback to earn back any points lost during the first submission. The project grade will be broken down as follows: Proposal &amp; Scoping: 10% Background &amp; Model Design: 15% Prototype Model: 15% Refinement &amp; Analysis: 20% Final Report &amp; Presentation: 40% Being an elective, it means you all have different levels of preparation for this course. Grades will focus on your growth rather than comparisons to other students. Admin Every Friday will be project work. Either setting the groundwork for your project or delivering a milestone. This Friday - come with a rough idea of what system you’d like to model/simulate. We’ll use the class time to workshop the idea. There will be a graded Canvas discussion board where you will need to drop your idea into. "],["week-1-what-is-modeling.html", "Chapter 2 Week 1: What is Modeling? 2.1 What we will be doing this week 2.2 Learning Objectives 2.3 Do, Watch, Listen, Read: Student Preparation For The Week 2.4 Let’s Build a Model of Learning 2.5 What Is Systems Thinking and Simulation? 2.6 Abstraction—and Why Is It So Hard? 2.7 The Problem-Solving Process 2.8 Intro to Prompt Engineering", " Chapter 2 Week 1: What is Modeling? Theme: Orientation, purpose of modeling, and first steps in RStudio Goal: Set a positive tone, introduce modeling as a mindset, and start building confidence with tools like RStudio and LLMs. 2.1 What we will be doing this week Wed: Welcome, course expectations, and an introduction to modeling as a way of thinking about systems. We’ll define what a model is and why it’s useful in environmental science. You’ll also begin brainstorming the systems you’re most interested in. Thu: Build and sketch simple conceptual models. We’ll talk about abstraction, simplification, and assumptions. You’ll draw your own system and explore a visual tool like LOOPY. Fri: Begin working in RStudio! We’ll introduce the platform, walk through a tutorial, and use an LLM to help you write your first line of R code. This day is all about taking that first step—together. Brainstorm and team up for class projects. 2.2 Learning Objectives By the end of Week 1, students should be able to: Define what a model is and explain its purpose in environmental science. Identify abstraction, simplification, and assumptions in a given model. Sketch and describe a simple conceptual model of a natural system. Critically assess the usefulness and limitations of models. Navigate basic RStudio functions and use LLMs to scaffold a simple model script. Start to formulate your projects 2.3 Do, Watch, Listen, Read: Student Preparation For The Week 2.3.1 Download and Install RStudio Go the the following link to download RStudio RStudio Desktop Download Note: Scroll down to find windows/mac version Be sure to get RStudio - not R, RStudio includes everything you need and it creates a much easier user interface to work with Now don’t worry - the expectation for this course is you have never worked with a coding language before. The purpose of this course is to offer a low stakes way to engage with coding and modeling, see its potential, and then take several other courses that focus on coding. 2.3.2 Do this tutorial Before we can explore the environmental systems we care about—like climate change, conservation, and sustainability, we need tools to help us think clearly and creatively. One of those tools is RStudio. Let’s be honest: learning a new programming environment can feel overwhelming. That’s okay. It’s normal to feel stuck, confused, or even frustrated when you’re starting out. But here’s the truth: We don’t get to do cool science or explore new ideas without doing hard things first. This tutorial will walk you through the basics of RStudio: how it looks, how to run code, and how to get started. You don’t need to master everything right away—just take it one step at a time. We’ll practice together in class, and you’ll have support from me, your peers, and even AI tools along the way. 2.3.3 5min Read Study Confirms Climate Models are Getting Future Warming Projections Right 2.4 Let’s Build a Model of Learning This is the way I see your learning. It’s a simple feedback between coming to class and office hours. Activity: What Drives Learning, Enjoyment, and Science? Your First Model: A Feedback Loop The diagram you’re looking at is called a systems model—specifically, a causal loop diagram. It’s the kind of model we use to: Represent complex systems using simple relationships Visualize feedback (both positive and negative) Experiment with how change flows through a system In this case, the system is about you as a learner. What’s Going On Here? Learning increases Enjoyment, which in turn increases Science. Factors can be added (green nodes) or subtracted (red nodes) from each part of the system. You can interact with the model by dragging the slider or clicking the nodes to see what happens. Task This is the first model of the course—and it’s about you. Your task: Play with the model: What happens when you increase the positive input? What if something subtracts from learning? As a group, add ideas to these categories: -What adds to your learning? What subtracts from your learning? Sketch your own version of the loop: What would you add to the system to help you succeed in this class? Can you identify a feedback loop (something that reinforces itself)? What’s something that could make the system spiral negatively? Wrap-up Discussion What surprised you about how small changes affected the system? How could this approach be used to model an environmental system? 2.5 What Is Systems Thinking and Simulation? Systems thinking is about seeing the world as an interconnected web of relationships—where change in one part of a system can ripple through others in surprising ways. It’s a mindset that helps us understand the feedback loops, delays, and patterns that shape everything from ecosystems and climate to cities and communities. Simulation is how we bring those systems to life. It’s the process of building simplified, dynamic representations of complex systems so we can ask questions, test scenarios, and explore “what if” ideas—without needing to experiment in the real world. Simulations help us: Focus on what really matters in a system Explore how change unfolds over time Make the invisible visible Together, systems thinking and simulation allow us to understand environmental challenges more deeplyand to imagine and test solutions before we act. In this course, we’ll use both to explore systems you care about, from forest ecosystems to climate strategies and sustainable cities. 2.6 Abstraction—and Why Is It So Hard? Abstraction is the process of simplifying a complex reality by focusing only on the parts that matter most for a specific question or purpose. It’s about stripping away detail so you can see the system more clearly. That might sound simple—but it’s not. In science (and in life), we’re surrounded by messy, interconnected realities. When we build a model or design a simulation, we have to decide: What do we include? What do we leave out? What assumptions are we making? Those are hard decisions. There’s no single “right” answer. Every abstraction involves a trade-off between realism and usability. Too simple, and the model might be useless. Too complex, and it might be impossible to understand or use. But here’s why abstraction matters: It’s the starting point for every scientific model, every simulation, every breakthrough idea. Abstraction helps us: Make sense of overwhelming complexity Communicate ideas clearly Focus our attention on what’s driving change Build models we can analyze, test, and improve Every person’s model will be different because of the unique structure and assumptions they make along the way. That’s not a problem—it’s what makes modeling so powerful and flexible. In climate modeling for instance, they way we create projections of future climates is by taking the average response of many climate models to a expected change in forcings. Sketching Exercise A sketch is a visual model. Task: Draw a picture of a chair Share your picture with those around you What assumptions did you all make in your model Which sketch was right? 2.7 The Problem-Solving Process At the heart of modeling and simulation is a desire to solve real-world problems—questions about climate, conservation, cities, and sustainability that don’t have simple answers. To tackle those problems effectively, we need a clear and flexible process. Here’s a step-by-step framework we’ll use throughout this course: 2.7.1 Define the Problem Start by clearly stating: What system are you trying to understand or improve? What question are you trying to answer? Who is affected by this problem, and why does it matter? Example: “How can we reduce the urban heat island effect in our city?” 2.7.2 Simplify and Abstract No model can capture every detail. So ask: What are the key components of this system? What can we leave out (at least for now)? What assumptions are we making? This is where abstraction comes in—choosing what to keep and what to simplify so that the model is useful without being overwhelming. 2.7.3 Build a Conceptual or Mathematical Model Now sketch or code a model that represents the system: Use diagrams, equations, or simulations Identify feedbacks, delays, and influences Decide how time and change are represented This is where your system takes shape. 2.7.4 Simulate and Explore Run your model. Ask: What happens when you tweak variables? Are the results stable, surprising, or sensitive? Does this align with what you expected—or challenge it? Simulation helps us test our ideas before we act in the real world. 2.7.5 Evaluate and Refine A model is never “finished.” It’s a tool for learning. What are the model’s strengths and weaknesses? How could it be improved? What new questions did it raise? Sometimes refining the problem is just as important as refining the solution. Science is often getting to the next why? 2.7.6 Communicate Even the best model won’t make a difference if no one understands it. Can you explain your model clearly—visually, verbally, or interactively? Who needs to hear this, and how should you frame it? Good science isn’t just about building models—it’s about sharing them. By following this process, you’re not just solving technical problems—you’re learning how to think critically, collaborate effectively, and design solutions that matter. 2.8 Intro to Prompt Engineering Before we dive into RStudio, we need to learn a surprisingly powerful skill: how to talk to AI. When we use tools like ChatGPT or Copilot, the results we get depend entirely on how we frame the question. This practice—designing questions and instructions for an AI—is called prompt engineering. Good prompts: Give clear context State what you’re trying to do Are specific, but not overloaded with details Might include examples or data structure Here’s the difference: ❌ Less helpful prompt: “How do I R?” ✅ More helpful prompt: “I’m working in RStudio. I have a dataset called CO2, and I want to make a scatter plot of uptake vs. concentration. Can you show me the code?” 2.8.1 Why This Matters Prompt engineering isn’t just about getting the right code—it’s about learning how to collaborate with AI to think through problems. In this course, you’ll use LLMs to: Get unstuck when your code won’t run Try new ideas quickly Explore how changing your prompt changes the response And just like with any tool, the more thoughtfully you use it, the better it works. Dataset Spotlight: CO₂ Uptake in Grass Plants About the Experiment The \\(CO_2\\) dataset comes from a classic plant physiology experiment that measured how grass plants respond to different concentrations of carbon dioxide under varying conditions. Researchers wanted to understand how \\(CO_2\\) levels , plant type , and treatment (chilled vs. non-chilled) affected the rate at which plants take up carbon from the atmosphere—a key part of understanding photosynthesis and climate-plant interactions. Specifically, they measured \\(CO_2\\) uptake in grass plants from two groups: Quebec (cooler climate) Mississippi (warmer climate) Some plants were kept at normal temperatures, while others were chilled to simulate colder conditions. The goal was to see how these factors influenced carbon uptake at different CO₂ concentrations. Dataset Structure This dataset includes 84 observations and 5 variables: Variable Description Plant Identifier for the individual plant (Qn or Mn, where Q = Quebec, M = Mississippi) Type Origin of the plant: \"Quebec\" or \"Mississippi\" Treatment \"chilled\" or \"nonchilled\" (i.e., whether the plant was cooled) conc CO₂ concentration in the ambient air (in mL/L) uptake Rate of CO₂ uptake (μmol/m²/s) – this is the response variable Why It’s Useful for Us This dataset is a great first modeling tool because it’s: Small and easy to understand Rich enough for meaningful patterns Great for visualization, group comparisons, and *basic regression modeling** A real-world example of how environmental variables interact "],["week-2-llms-and-modeling-support.html", "Chapter 3 Week 2: LLMs and Modeling Support 3.1 Learning Goals 3.2 Do, Watch, Listen, Read: Student Preparation for the Week 3.3 Introduction to LLMs in Modeling (Mon) 3.4 Capabilities and Limits of LLMs 3.5 LLMs in Environmental Modeling Workflows 3.6 Prompt Engineering for Model Development (Tue &amp; Wed) 3.7 Learning goals 3.8 Principles of effective prompts: clarity, context, constraints 3.9 Prompt types: zero-shot, few-shot, role-based (with modeling examples) 3.10 Iterative refinement and debugging prompts (the LEI loop) 3.11 ADE Prompt Library &amp; Activity 3.12 Critical Reflection: When to Use AI Tools 3.13 Reproducibility, Documentation, and Troubleshooting (Fri) 3.14 First Model - ADE", " Chapter 3 Week 2: LLMs and Modeling Support 3.1 Learning Goals By the end of this week, students should be able to: Explain what large language models (LLMs) are and how they can support simulation and coding. Apply prompt engineering techniques to improve model development. Use LLMs to reframe and clarify environmental modeling challenges. Critically evaluate when and how it is appropriate to use AI tools in science. Incorporate LLMs into workflows for reproducibility, documentation, and troubleshooting in R. 3.2 Do, Watch, Listen, Read: Student Preparation for the Week 3.2.1 Do Open an LLM tool (ChatGPT, Claude, Gemini and ask it to: Explain a simple scientific concept (e.g., greenhouse effect) in plain language. Write R code to simulate 10 years of daily temperature with a slight warming trend. Compare the outputs: What worked well? What didn’t? 3.2.2 Watch: Video for Discussion Video: Master 80% of Prompt Engineering In 10 Minutes! (YouTube, 2024) Intro: This short video introduces the foundations of prompt engineering and then builds into practical strategies. It explains the core elements of a good prompt, highlights three advanced techniques, and shares a few bonus tips for refining outputs. The goal is to show how structured, intentional prompting can make AI much more useful in practice—especially for coding, modeling, and explanation tasks. Questions to Ponder While Watching: What are the “core elements” of prompt design highlighted in the video? Why are they essential? Which advanced technique seems most useful for environmental modeling tasks (e.g., generating R code, simulation explanations)? How might you apply one of the bonus tips when working on your Week 2 activities? Can you think of a situation where a poorly written prompt could cause confusion or errors in scientific modeling? How would you fix it? 3.2.3 Read: Reading for Discussion Article: Reconciling the contrasting narratives on the environmental impact of large language models (Nature Scientific Reports, 2024) Intro: As we consider how to use large language models (LLMs) in environmental science, it’s important to recognize that these tools themselves have environmental costs. This article examines the energy use and carbon footprint of training and running LLMs, compares them with human labor, and discusses how different assumptions lead to contrasting narratives about their sustainability. It’s a nuanced look at the trade-offs between the benefits of AI and the resources required to power it. Questions to Ponder While Reading: What are the main sources of environmental impact from LLMs (training vs. deployment)? How do the authors compare the impacts of LLMs to traditional human-driven approaches? Which assumptions (e.g., electricity sources, hardware lifespans) most influence the conclusions? How might these trade-offs shape your perspective on using LLMs in scientific modeling workflows? These materials will help you see both sides of using LLMs: as a tool for speeding up coding and simulation, and as a system with important limits you must understand as a scientist. 3.3 Introduction to LLMs in Modeling (Mon) Large language models (LLMs) are a new class of tools that can transform the way scientists and students approach coding, simulation, and communication. They are not replacements for human expertise, but they can act as collaborators—helping us generate ideas, translate complex models into accessible explanations, and troubleshoot code. In this chapter, we explore what LLMs are, how they developed, and how they connect to environmental modeling workflows. 3.3.1 What Are LLMs? A large language model (LLM) is a type of artificial intelligence system trained on massive collections of text. The core idea is surprisingly simple: given a sequence of words, the model predicts the most likely next word. By stacking billions of parameters and training on billions of words, LLMs learn patterns of grammar, style, reasoning, and even coding syntax. Think of an LLM as a highly advanced autocomplete. Instead of only finishing a single word, it can continue a sentence, draft an essay, write a block of R code, or explain a scientific model in plain language. 3.3.2 A Brief History Early 2010s: Models such as word2vec and GloVe mapped words into mathematical space, capturing similarities (“river” is close to “stream”). 2017: The transformer architecture was introduced, allowing models to learn long-range patterns in text. 2018–2020: OpenAI’s GPT-2 and GPT-3 showed that scaling up data and parameters led to dramatic improvements in fluency. 2022–present: Public releases of GPT-4, Claude, Gemini, and other models made LLMs widely accessible for coding, writing, and research. This rapid evolution means today’s students can use tools that did not exist even a few years ago. Discussion What do you think an appropriate use of LLMs are. Discuss with your table and lets see if we can build some community guidelines (for this class and beyond) 3.4 Capabilities and Limits of LLMs 3.4.1 Capabilities One of the reasons LLMs have gained such traction in research and education is their versatility. They are capable of generating readable text in many different styles, ranging from concise scientific summaries to conversational explanations that make technical concepts more approachable. This flexibility allows them to adapt their tone depending on the intended audience, whether it is a group of peers, policymakers, or the general public. Beyond writing, LLMs are particularly useful for producing and troubleshooting code across multiple languages, including R, Python, and MATLAB. Students working through simulations can quickly draft starter scripts, identify syntax errors, or explore alternative approaches to the same problem. In addition, LLMs can act as powerful summarization tools, condensing long articles, large datasets, or complex equations into clear, digestible insights that highlight key trends or ideas. Finally, perhaps one of their most accessible features is the ability to translate technical content into plain language, making specialized knowledge understandable to non-experts. This capacity to bridge the gap between complexity and clarity is especially valuable in environmental science, where communicating models and data to diverse audiences is critical for impact. 3.4.2 Limits Despite their impressive capabilities, LLMs come with important limitations that must be acknowledged. A well-documented issue is hallucination, where the model generates text that sounds plausible but is factually incorrect or even entirely fabricated. This can be especially problematic in scientific work, where accuracy is paramount. LLMs also reflect the biases present in their training data, which means that outputs may unintentionally reproduce stereotypes or emphasize certain perspectives while ignoring others. Another limitation is that these systems lack true reasoning or understanding—they do not “know” science in the way humans do, but instead predict patterns based on statistical relationships in text. This means their explanations can oversimplify concepts or miss critical assumptions. Finally, there are reproducibility challenges, since the same prompt can yield slightly different outputs depending on the model and context, making it harder to standardize results for scientific workflows. Recognizing these limits helps ensure that we use LLMs critically, as aids to human reasoning rather than substitutes for it. Reflection Prompt Think about a task in environmental modeling you’ve worked on recently (coding, data analysis, or communicating results). Which of the capabilities described here could have supported your work? Which limitations would you need to watch out for? How might you balance the efficiency of using an LLM with the need for accuracy and scientific rigor? 3.5 LLMs in Environmental Modeling Workflows How do LLMs connect to the practice of environmental modeling? Their utility lies not in replacing the scientist, but in serving as a flexible assistant at different stages of the workflow. One of the most immediate applications is code generation. For instance, a student working on a logistic population growth model in R can prompt an LLM to draft the basic script. Even if the generated code is not perfect, it provides a working foundation that can be edited and refined, reducing the time spent on tedious setup. Similarly, LLMs can assist with documentation support. In RMarkdown or other coding environments, clear documentation is essential for reproducibility, yet students often overlook it. By asking an LLM to add explanatory comments, create section headers, or translate code into step-by-step descriptions, the workflow becomes easier to follow both for the original author and for future collaborators. Another important use is simulation explanation. Equations that may appear abstract to non-specialists—such as those describing exponential growth, diffusion, or temperature response—can be reframed by an LLM into accessible narratives. For example, the logistic growth equation can be explained as a story of a population that grows quickly at first but slows as resources become scarce, eventually leveling off at a carrying capacity. These applications highlight the potential of LLMs to streamline scientific work: they can help students start coding more quickly, reduce frustration by catching errors or filling in gaps, and make models more communicable to a wider audience. At the same time, none of these tasks can be fully delegated without oversight. Generated code must be tested for accuracy, documentation must be checked for completeness, and plain-language explanations must be reviewed to ensure they do not omit critical assumptions. In this way, LLMs become collaborative tools that support efficiency and clarity while keeping the responsibility for scientific rigor firmly in human hands. Activity: Explain a Complex Model with Stepwise Prompting We’ll use stepwise (chain-of-thought–style) prompting to unpack a very complex partial differential equation into clear, audience-appropriate language without asking the AI to reveal its private reasoning. The goal is to force a structured, term-by-term explanation and surface assumptions. Note: we are purposefully using a complex example here so that we can really see the value and dangers of utilizing a LLM for environmental modeling. Model The Advection–Diffusion (or Dispersion) Equation for pollutant transport in a river: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] - \\(C\\): concentration at position \\(x\\) and time \\(t\\) - \\(D\\): diffusion coefficient (mixing) - \\(v\\): flow velocity (downstream transport) - \\(k\\): decay rate (removal) Step 1 — Your Own Explanation Write a plain-language explanation for a non-scientist audience (e.g., a community group). If you have no idea whats going on - take a guess. Go term by term and see if you can decipher whats going on. Step 2 — Baseline AI Explanation Ask an LLM for a plain-language explanation. Save the response. Baseline prompt: Explain the equation below in plain language for a non-scientist audience. \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Keep it to 6–8 sentences. Take a second here and compare your result with those at your table? Are thy idenitical? Step 3 — Stepwise Prompting (Structured Sections) Now force structure so the AI unpacks complexity term-by-term and surfaces assumptions. Stepwise prompt template (copy-paste) Explain the equation below using labeled sections. Do not show your internal reasoning; present only your final explanation. Sections (use headings): 1) Term-by-term meaning — explain each term in one sentence. 2) Physical interpretation — connect each term to a river process with a brief analogy. 3) Assumptions — list key modeling assumptions (e.g., dimensionality, parameter constancy, uniform mixing). 4) Units &amp; parameters — specify typical units for \\(C, D, v, k\\). 5) Edge cases — describe what happens if \\(D=0\\), \\(v=0\\), or \\(k=0\\). 6) Plain-language summary — 3 sentences for a public audience. Equation: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Step 4 — Compare &amp; Critique Clarity: Which version (baseline vs. stepwise) is clearer and why? Completeness: Did the stepwise version expose assumptions or units the baseline missed? Accuracy: Note any incorrect claims or overconfidence. Most importantly - which version did you learn something from? Step 5 — Constraint Refinement Re-prompt with tighter constraints to match a specific audience. Audience-tuning examples Policy brief style (≤150 words, 8th-grade reading level). Technical appendix style (include parameter ranges and citations placeholder). Infographic caption style (≤90 words, 3 bullets + 1 summary sentence). Step 6 — Mini-Deliverable Submit: (1) your own explanation, (2) baseline AI output, (3) stepwise output, (4) a 3–5 bullet critique comparing them, and (5) one audience-tuned version. Extension (optional) Ask the AI to propose a simple diagram description (no image needed): axes, arrows for diffusion/advection, and a decay cue. Use this as a storyboard for a figure you might create later. 3.6 Prompt Engineering for Model Development (Tue &amp; Wed) Principles of effective prompts: clarity, context, constraints. Prompt types: zero-shot, few-shot, role-based prompts. Iterative refinement and debugging prompts. Activity: Students write and test prompts for generating R code to simulate temperature data. 3.7 Learning goals By the end of today, students will be able to: - craft clear, contextualized, and constrained prompts that produce correct code and documentation; - select and combine zero-shot, few-shot, and role-based prompts for modeling tasks; - iteratively refine outputs using structured critique, unit tests, and debugging prompts; - apply these skills to build and explain a simple advection–diffusion–decay (ADE) model in R. 3.8 Principles of effective prompts: clarity, context, constraints Clarity (goal + audience): State the task and who it is for. “Write R code for first-year environmental science students.” Context (problem + assumptions): Include the equation, domain, units, and assumptions. “1-D ADE, L = 10 km, v = 0.2 m/s, D = 10 m²/s, k = 1e-5 s⁻¹, Dirichlet at x = 0, Neumann at x = L.” Constraints (format + checks): Specify interfaces, style, tests, plots, and failure modes. “Return a function run_ade(params); add a CFL check; produce one line plot and one time-series plot; comment every major step.” Success criteria: Tell the model how you will judge success. “Code must run without additional packages beyond ggplot2 and dplyr.” Prompt template ASK: &lt;what to build/explain&gt; CONTEXT: &lt;equations, domain, units, assumptions&gt; CONSTRAINTS: &lt;APIs, style, allowed packages, runtime, plots&gt; CHECKS: &lt;tests/diagnostics to include&gt; OUTPUT FORMAT: &lt;function name, file structure, markdown section, etc.&gt; AUDIENCE: &lt;novice, advanced, instructor notes&gt; 3.9 Prompt types: zero-shot, few-shot, role-based (with modeling examples) Zero-shot — no examples, just a precise specifiction (spec) “Implement a Crank–Nicolson diffusion step and 1st-order upwind advection for the 1-D ADE; include a CFL diagnostic and return a tibble of (time_h, x, C).” Few-shot — show a small, high-quality example to anchor style/format. Provide a short example of a function signature and one test, then ask for an analogous function for ADE. Role-based — assign the model a persona to set expectations and tone. “You are a hydrology TA. Produce commented, teachable R code and insert two discussion questions that probe assumptions.” When to mix: Start role-based + zero-shot to draft; add few-shot when you need consistent structure (e.g., identical plotting themes across labs). 3.10 Iterative refinement and debugging prompts (the LEI loop) L — Launch a first draft with strict constraints. E — Evaluate using tests, plots, and quick sanity checks (mass balance, units, stability numbers). I — Iterate with targeted prompts: Examples: “Diagnose: Why does concentration become negative near the boundary? Propose two fixes and implement the safer one.” “Add input validation: stop with a clear message when CFL &gt; 0.9 or when D &lt; 0.” “Refactor into setup_grid(), step_CN(), step_advect(), apply_decay(). Return a named list.” “Generate three unit tests using testthat for: CFL computation, Neumann boundary, non-negative concentration.” “Write a 5-line docstring explaining assumptions and limitations for non-experts.” 3.11 ADE Prompt Library &amp; Activity Our goal is to build and explain a simple Advection–Diffusion (ADE) model in class using careful prompts and iterative refinement. 3.11.1 What you’ll build (at a glance) An R function run_ade(params) that simulates \\[ \\frac{\\partial C}{\\partial t} \\;=\\; D\\,\\frac{\\partial^2 C}{\\partial x^2} \\;-\\; v\\,\\frac{\\partial C}{\\partial x} \\;-\\; k\\,C \\] on \\([0,L]\\) with Dirichlet at \\(x=0\\) and zero-gradient (Neumann) at \\(x=L\\). Built-in checks for CFL and diffusion number \\(r_D\\). Two plots: (i) spatial profiles at selected times, (ii) time series at stations. Short, plain-language documentation of assumptions and limitations. 3.11.2 Spec → Code Write an R function run_ade(params) that simulates the 1-D advection–diffusion equation \\[ \\frac{\\partial C}{\\partial t} = D\\,\\frac{\\partial^2 C}{\\partial x^2} - v\\,\\frac{\\partial C}{\\partial x} - k\\,C \\] on the domain \\([0, L]\\) with Dirichlet at \\(x=0\\) and zero-gradient (Neumann) at \\(x=L\\). Include: a CFL check, diffusion number \\(r_D\\), two plots (profiles and station time-series), and comments suitable for first-year students. 3.11.2.1 Explain assumptions In 5 bullets, state modeling assumptions (dimensionality, parameter constancy, mixing, linear decay) and one situation where each assumption breaks. 3.11.2.2 Stability &amp; units Add a helper diagnostics() that prints CFL, Péclet, and a units table (C in mg/L, v in m/s, D in m²/s, k in 1/s). Warn when CFL &gt; 0.9. 3.11.2.3 Visualization Plot profiles at \\(t=\\) 0, 1, 3, 6 h and time-series at \\(x=\\) 1, 5, 9 km. Use clear axis labels and a legend; keep plotting code under 20 lines. In-class group activity (45–50 min): “Prompt → Plan → Build → Verify” Uses chain-of-thought prompting safely by asking the model to output a plan (step list/pseudocode) before code. Deliverables: prompt(s), plan, R script, two plots, short reflection. 3.11.2.4 Common pitfalls &amp; how to prompt around them Vague goals → meandering code → “Limit the solution to one function run_ade; ≤ 80 lines; include two plots and a diagnostics print.” Hidden assumptions → “List all assumptions you made; mark each as ‘required’ or ‘replaceable’.” Boundary errors → “Explain, in words, how you implement Dirichlet at \\(x=0\\) and zero-gradient at \\(x=L\\); then show the exact index operations.” Numerical instability → “Compute and print CFL and \\(r_D\\); if CFL &gt; 0.9, automatically shrink dt and state the new value.” Over-fancy output → “No external packages beyond ggplot2/dplyr; avoid themes; keep defaults.” 3.12 Critical Reflection: When to Use AI Tools Deciding when to use an LLM is not always straightforward. These tools offer powerful benefits but also come with risks and ethical concerns. As environmental scientists, we need to think critically about how AI fits into our workflows and how it might affect the quality, accessibility, and trustworthiness of science. 3.12.1 Benefits LLMs can accelerate many parts of the research process. They provide speed, helping draft code, summaries, or explanations in seconds. They also increase accessibility, lowering the entry barrier for students or collaborators who may not yet have advanced coding or writing skills. LLMs often spark creativity, generating new ways of framing a problem or suggesting approaches we might not have considered. Finally, they offer support for non-experts: a student new to modeling can use an LLM to explain equations or code in plain language, building confidence and understanding more quickly. 3.12.2 Risks and Limits At the same time, AI-generated content comes with important limitations. The most pressing concern is accuracy: LLMs can produce convincing but incorrect answers. This problem, often called hallucination, makes it dangerous to rely on AI outputs without verification. Models also inherit biases from their training data, which can shape the tone, assumptions, or inclusivity of their responses. There are also ethical concerns, including the environmental cost of training large models, the potential for plagiarism or misuse, and broader questions about authorship and credit in scientific work. Recognizing these risks is essential for responsible use. 3.12.3 Guidelines for Responsible Use in Environmental Science To make AI a constructive tool rather than a crutch, we can follow a few guidelines: Use AI to support, not replace, expertise. Treat LLMs as collaborators that generate drafts, not as authorities. Verify and validate outputs. Always test AI-generated code and fact-check explanations. Document when AI was used. Transparency helps others understand how results were created. Consider the audience. Decide whether an AI-generated explanation is appropriate for a scientific paper, a classroom activity, or public communication. Reflect on ethics. Think about sustainability, fairness, and responsible authorship when integrating AI into research. Debate — Should We Use AI in Research? Divide into groups. Half the class argues for using LLMs in environmental research, and half argues against. Use examples from your own experience and the guidelines above. After the debate, reflect as a group: Which arguments were most persuasive? What conditions or safeguards make AI use acceptable? Where should we draw the line between helpful assistance and over-reliance? 3.13 Reproducibility, Documentation, and Troubleshooting (Fri) Using LLMs to improve reproducibility: RMarkdown templates, commenting code, documenting decisions. Hands-on: Simulate a simple temperature model in R (linear warming trend + random noise). Use LLMs for: - Suggesting code improvements. - Adding explanations and comments. - Identifying potential reproducibility pitfalls. Reflection: How does AI support or hinder scientific reproducibility? 3.14 First Model - ADE The advection–diffusion equation (ADE) is a fundamental tool in environmental science for describing how substances such as pollutants, heat, or nutrients move and transform in natural systems. It combines three processes — advection (transport by bulk flow), diffusion (spreading due to mixing or molecular motion), and decay (loss by reaction, degradation, or uptake). Together, these processes govern how concentrations change in space and time. 3.14.1 General Form In one spatial dimension, the ADE is written as: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] where: - \\(C(x,t)\\) = concentration of the substance at location \\(x\\) and time \\(t\\) - \\(D\\) = diffusion (or dispersion) coefficient \\((\\text{L}^2/\\text{T})\\) - \\(v\\) = advective velocity (bulk flow speed, \\(\\text{L}/\\text{T}\\)) - \\(k\\) = decay rate constant \\((1/\\text{T})\\) This is a partial differential equation (PDE) because it describes how concentration changes both with respect to time (\\(t\\)) and space (\\(x\\)). 3.14.2 Term-by-Term Meaning Diffusion Term \\((D \\frac{\\partial^2 C}{\\partial x^2})\\): Captures the natural tendency of a substance to spread out, whether through molecular diffusion (random particle motion) or turbulent mixing. In rivers, this reflects how pollutants disperse laterally and longitudinally. Advection Term \\((-v \\frac{\\partial C}{\\partial x})\\): Represents bulk transport due to flow. In a river, advection moves pollutants downstream at approximately the mean flow velocity. Decay Term \\((-kC)\\): Accounts for processes that remove the substance over time. Examples include radioactive decay, microbial degradation of organic matter, or chemical reactions that break down contaminants. 3.14.3 Assumptions Behind the ADE Like all models, the ADE relies on simplifying assumptions: 1. Homogeneity of parameters: \\(D\\), \\(v\\), and \\(k\\) are assumed constant in space and time. 2. One-dimensional flow: The river or system is treated as a single streamline, ignoring lateral and vertical variation. 3. Continuum assumption: Concentration is treated as a smooth, continuous field rather than individual particles. 4. Linear processes: Each term acts independently and linearly, with no feedbacks or nonlinear effects. These assumptions make the equation mathematically tractable, but real systems often require adjustments or numerical solutions to capture complexity. 3.14.4 Applications in Environmental Science Rivers and Streams: Tracking the downstream fate of pollutants (e.g., nutrients, heavy metals, thermal plumes). Atmosphere: Modeling dispersion of air pollutants under wind flow and turbulent mixing. Groundwater: Describing contaminant transport through porous media. Oceans and Lakes: Simulating nutrient plumes or thermal pollution. In each case, the relative importance of advection, diffusion, and decay depends on system parameters. A fast river with low diffusion behaves differently than a stagnant pond with strong decay. 3.14.5 Analytical Solutions For simple cases, the ADE has analytical solutions. A classic example is the instantaneous point source (a sudden spill at \\(x=0\\), \\(t=0\\)) in an infinite domain: \\[ C(x,t) = \\frac{M}{\\sqrt{4\\pi D t}} \\exp \\left( -\\frac{(x - vt)^2}{4Dt} - kt \\right) \\] where \\(M\\) is the mass released. This solution shows a Gaussian plume that spreads (due to diffusion), shifts downstream (due to advection), and decreases in height (due to decay). 3.14.6 Numerical Solutions For realistic boundary conditions (finite rivers, variable flows), numerical methods such as finite difference, finite element, or particle tracking are used. These methods discretize space and time, approximating how concentration evolves step by step. 3.14.7 Key Dimensionless Numbers Two ratios help characterize transport: Péclet Number (\\(Pe\\)): \\[ Pe = \\frac{vL}{D} \\] Ratio of advection to diffusion. High \\(Pe\\) means transport is dominated by flow. Damköhler Number (\\(Da\\)): \\[ Da = \\frac{kL}{v} \\] Ratio of reaction/decay to advection. High \\(Da\\) means rapid decay compared to transport. Together, \\(Pe\\) and \\(Da\\) guide whether a pollutant plume will spread, persist, or disappear quickly. 3.14.8 Visualization Low velocity, high diffusion: plume spreads symmetrically around the release point. High velocity, low diffusion: plume moves downstream as a narrow band. Strong decay: plume shrinks and may vanish before traveling far. 3.14.9 Reflection Questions Which term (advection, diffusion, or decay) dominates in a fast-flowing river vs. a still pond? How does increasing \\(D\\) change the shape of a pollution plume? What are the consequences of assuming one-dimensional flow when rivers have significant lateral mixing? How might climate change (altered flow velocities, higher temperatures) affect ADE parameters? "],["app-wk1.html", "Appendix A Project Week 1 – The ‘why’ and the ‘what’", " Appendix A Project Week 1 – The ‘why’ and the ‘what’ \\(Y^n\\) Pick a system and ask why about some part you are interested Then ask a why again Keep asking why till you cant find the answer anymore Quick Demo Why does day length change? → Because of the seasons. As Earth orbits the Sun, sometimes your hemisphere is tilted toward the Sun (summer, longer days) and sometimes away (winter, shorter days). Why do we have seasons? → Because of the tilt of Earth’s axis. Earth’s axis is tilted about 23.5° relative to its orbit. This tilt changes how high the Sun appears in the sky and how long its path lasts each day. Why is Earth tilted? → Because of a giant collision in the early solar system. A Mars-sized body (often called Theia) likely struck Earth 4.5 billion years ago. This impact knocked Earth off a straight-up orientation and also produced the Moon. Why did that collision happen? → Because the early solar system was chaotic. When the Sun first formed, space around it was full of rocky planetesimals (early building blocks of planets). Their orbits overlapped, and gravity pulled them into frequent, violent collisions. Why was there a disk of planetesimals in the first place? → Because the solar system formed from a collapsing nebula. A cloud of gas and dust collapsed under gravity. As it collapsed, conservation of angular momentum caused the material to flatten into a spinning disk. Inside that disk, clumps grew into planetesimals and then planets. Why does the Earth spin in the first place? → Because of angular momentum inherited from the disk. The collapsing nebula was already rotating. As clumps of matter formed into planets, they retained that spin. Collisions and impacts modified Earth’s rotation rate and axis, but didn’t stop the overall spin. Why did the nebula collapse? → Because of gravity and outside triggers. Dense regions of interstellar gas clouds naturally collapse under their own weight. This process may have been accelerated by shock waves from a nearby supernova explosion. Why was there a cloud of gas and dust? → Because of earlier generations of stars. Stars burn fuel and die. Supernovae scatter their contents into space, creating gas and dust clouds rich in heavy elements. Our solar system is made of this recycled stardust. Why do stars form and die? → Because of gravity and nuclear fusion. Gravity compresses gas until fusion ignites. Fusion powers stars until the fuel is gone, at which point they evolve into white dwarfs, neutron stars, or black holes. Why does nuclear fusion work? → Because of the fundamental forces of nature. Fusion is governed by gravity, electromagnetism, and the strong/weak nuclear forces. These make it possible for nuclei to fuse and release energy. Why do these fundamental forces exist, and why do they have the values they do? → That is an open question. Physics describes and measures these forces, but doesn’t explain why they exist at all. This is the frontier where science meets philosophy and cosmology. \\(Y^{11}\\) Task 1 - Group of 5 Workshop your individual ideas with your group Spend 3 mins on each person (I’ll set a timer) Ask y’s Task 2 - 1 Line Description Take a couple minutes and try to write down - in one line - where your idea is at. This is not your final project topic - just a progress report Post this after class in the discussion opened for project ideas [P&amp;P] Comment on 3 posts - ask another specific why? [P&amp;P] Task 3 - Network Find the like minded people in the room Team up? Couple your models? Share thoughts "],["workbook-week-1-what-is-modeling.html", "Appendix B Workbook Week 1: What is Modeling?", " Appendix B Workbook Week 1: What is Modeling? Class Discussion Lets build a working definition of the central components of this course. In your groups see if you can define Coding Models/Modeling Simulation Systems Logic Syntax A key skill in being a modeler is the ability of abstraction Sketching Exercise A sketch is a visual model. Task: Draw a picture of a chair (1min) Share your picture with those around you What assumptions did you all make in your model Which sketch was right? Systems Thinking - what do we mean by this? Lets do my phd in 5 mins - plants in desert systems - lets think about this as a system. Pseudo code The art of writing good instructions I’m a robot, and you want me to toast a bagel and put Vegemite on it. Write me the pseudo code to make this happen. This is what happens when you give bad instructions: This is what’s possible with complete instructions: Group activity - Dice We want to know what the most likely total you would get from rolling two 6 sided die. Write some pseudo code to collect data to help you work this out. Guessing Game Write pseudo code that would count how many guesses you would take to find a number between 1 and 10. Needle in a Haystack In the Dan Brown novel ‘Angels and Demons’ the Vatican is about to be blown up by a antimatter device. In the movie, the bad guys has a webcam on the device. Someone has the idea of systematically cutting power to the different sectors of the power grid to narrow down the location. They dismiss is because they work out there isn’t enough time to cycle through all the sectors. But you took my class and actually make this idea work. Lets assume: We have 1,048,576 possible sectors. It takes 1hr for a sector to respond to a change What’s the longest time it would take to find the sector? What is the shortest time it would take to be sure you found the sector? Write some pseudo code "],["workbook-week-2-llms.html", "Appendix C Workbook Week 2: LLMs C.1 How to Build Complixity into a Problem C.2 LLMs and Modeling Support", " Appendix C Workbook Week 2: LLMs C.1 How to Build Complixity into a Problem We briefly discussed the need to layer complexity when trying to model. Lets work through an example of that. Banksy’s Balloon Model Have you ever wondered what happens to a helium filled balloon that is released? What we will do is build a mathematical model of the balloon to help answer this question. What controls the height at which a the balloon will climb? \\[B(z) = f(\\] Abstraction What is the simplest form of the problem we could solve? What assumptions could we make to help us get started? Neutral Buoyancy Given the table below and the density information about helium. What height would the balloon get to? At sea-level conditions (about \\(T = 288\\,\\text{K}\\), \\(P = 101{,}325\\,\\text{Pa}\\)): Helium density: \\[ \\rho_{\\text{He}} \\approx 0.1785\\ \\text{kg/m}^3 \\] Evaluate and then add complexity Does this feel right? What assumptions did we make that might have been too simplistic? What math model could we apply to add complexity? Ideal Gas Law The ideal gas law relates the pressure, volume, temperature, and number of moles of a gas: \\[ PV = nRT \\] Definitions \\(P\\): Pressure of the gas (Pa or atm) \\(V\\): Volume of the gas (m³ or L) \\(n\\): Number of moles of gas (mol) \\(R\\): Ideal gas constant \\(8.314\\ \\text{J·mol}^{-1}\\text{·K}^{-1}\\) (SI units) \\(0.08206\\ \\text{L·atm·mol}^{-1}\\text{·K}^{-1}\\) (common chemistry units) \\(T\\): Absolute temperature (Kelvin, K) Notes - The equation assumes an ideal gas (no inter-molecular forces, particles take up negligible space). - Works well for helium and other light gases at normal temperatures and pressures. - Can be rearranged into useful forms, e.g. density: Flexible Balloon Let’s let the volume of the balloon change - removing the rigid balloon requirement. \\[ PV = nRT \\] Rearranging for n: \\[ n = \\frac{PV}{RT} \\] We know n can’t change as the balloon isn’t leaking. So we can think of the balloon in two places \\[ n_{msl} = n_{top} \\] so plug the rest in \\[ \\frac{P_1V_1}{T_1}=\\frac{P_2V_2}{T_2} \\] Ask ourselves what changes based on out assumptions What is going to happen to the volume of the balloon as it climbs? What happens to the density of helium if the volume increases? \\[ \\rho = \\frac{M}{V} \\] Evaluate - Does this make sense? The next thing is to model where the balloon will land. This tool uses the near term forecast as well as the balloon’s parameters to determine the most likely trajectory. SondeHub Flight Predictor C.2 LLMs and Modeling Support C.2.1 Learning Objectives By the end of this week, students should be able to: Explain what large language models (LLMs) are and how they can support simulation and coding. Apply prompt engineering techniques to improve model development. Use LLMs to re-frame and clarify environmental modeling challenges. Critically evaluate when and how it is appropriate to use AI tools in science. Incorporate LLMs into workflows for reproducibility, documentation, and troubleshooting in R. C.2.2 Coding warmup Pseudo-code and r script activity Create a script that fits a line of best fit to the following string of 10 numbers 6,1,7,2,3,3,9,3,3,0 Create the flexibility in the code to fit a nth order polynomial of your choosing. Before you run build an expectation What do expect the graph to look like with n=1 n=5 n=9 n=12 What evaluation tools/outputs could you create so that you can ‘test’ the output? Compare your expectations with your output Compare your outputs with the people around you C.2.3 What is a Large Language Model 1 min Discussion What is a LLM and how does it work? Class Discussion What are the dangers of highly parameterized model? Pros and cons of parameter counts? C.2.4 Pros and Cons of High-Parameter Models High-parameter (or “high-complexity”) models — like very high-degree polynomials, deep neural networks with many layers, or regression models with lots of predictors — have clear advantages and drawbacks. C.2.4.1 ✅ Pros Flexibility &amp; Expressiveness Can capture very complex relationships, including nonlinear patterns that simple models would miss. For example: a 9th-degree polynomial can fit 10 points exactly. Low Training Error With enough parameters, the model can drive error on the training set down to nearly zero. Useful if your goal is interpolation of the given data rather than generalization. Captures Subtle Structure Sometimes, especially with rich datasets, complexity helps reveal real underlying trends that simpler models would smooth over. C.2.4.2 ❌ Cons Overfitting The model fits noise as if it were signal. Predictions on new data are often unstable and inaccurate. Interpretability High-degree polynomials or models with many coefficients are hard to interpret or explain. Coefficients may be large, unstable, or counter-intuitive. Numerical Instability High-order polynomials can produce NAs or huge coefficients due to ill-conditioning. Small changes in input lead to large swings in output. Computational Cost More parameters = more computation, longer training, and sometimes risk of convergence issues. Generalization Risk High training accuracy doesn’t guarantee real-world usefulness. Models may fail badly outside the range of training data. C.2.5 Parameters in Large Language Models (LLMs) Large Language Models (LLMs) are defined in part by the number of parameters they contain — the trainable weights in their neural networks. These parameters are like knobs the model adjusts during training to learn patterns in data. C.2.5.1 ⚙️ Parameters in Modern LLMs GPT-2 (2019) → ~1.5 billion parameters GPT-3 (2020) → 175 billion parameters PaLM (Google, 2022) → 540 billion parameters GPT-4 (2023) → parameter count not officially disclosed, but estimates suggest hundreds of billions to over a trillion GPT-4 Turbo (2023, OpenAI API) → optimized variant, size undisclosed, but still in the “hundreds of billions” range Anthropic’s Claude 3 (2024) → not public, but assumed similar scale (hundreds of billions) Gemini Ultra (Google DeepMind, 2024) → also undisclosed, estimated trillion-scale C.2.5.2  What “Parameters” Mean Each parameter is just a number (a weight) that influences how input tokens get transformed through the layers of the neural net. More parameters = more capacity to model complex relationships, but also: Requires more data to train Much more compute (training GPT-3 took thousands of GPUs for weeks) Can increase risk of overfitting if not carefully regularized C.2.5.3  Trend in LLM Growth 2018–2020 → billions of parameters 2021–2023 → hundreds of billions 2024 onward → trillion+ parameter models (but with a shift toward efficiency — smaller models trained better) Contextualizing these large numbers 1 million seconds –&gt; 11.6 days 1 billion seconds –&gt; 31.7 years (~1.5 of your lifetimes) 1 trillion seconds –&gt; 31,700 years (~1,500 your lifetimes) C.2.5.4  Table: LLMs and Parameter Counts Model Year Parameters (approx.) Notes GPT-2 2019 1.5B First widely known OpenAI LLM GPT-3 2020 175B Major leap in scale PaLM (Google) 2022 540B Pathways Language Model GPT-4 2023 100B–1T (est.) Exact number undisclosed GPT-4 Turbo 2023 100B+ (est.) Optimized API variant Claude 3 (Anthropic) 2024 100B+ (est.) Scale similar to GPT-4 Gemini Ultra (Google) 2024 1T+ (est.) Trillion-scale model ✅ Summary: Modern LLMs like GPT-4, Claude 3, or Gemini are likely running in the hundreds of billions to trillions of parameters range. C.2.6 Capabilities and Limits of LLMs Discussion: What are the Capabilities and Limits of LLMs Reflection Prompt Capabilities and Limits of LLMs ✅ Capabilities of LLMs Generate readable text in many styles Scientific summaries Conversational explanations Adapt tone for peers, policymakers, or the public Produce and troubleshoot code Works across multiple languages (R, Python, MATLAB) Draft starter scripts, find syntax errors, explore alternatives Summarization tools Condense long articles, datasets, or equations Highlight key insights and trends Translate technical content into plain language Make specialized knowledge understandable to non-experts Support communication of environmental science to diverse audiences ⚠️ Limits of LLMs Hallucination Can produce text that sounds plausible but is factually wrong Bias in training data May reproduce stereotypes or skew perspectives Lack of true reasoning/understanding Predicts patterns statistically, not by scientific comprehension Explanations may oversimplify or omit key assumptions Reproducibility challenges Same prompt can yield different outputs Hard to fully standardize in scientific workflows Which of the capabilities described here could have supported your work? Which limitations would you need to watch out for? How might you balance the efficiency of using an LLM with the need for accuracy and scientific rigor? C.2.7 LLMs in environmental modeling workflows Activity: Explain a Complex Model with Stepwise Prompting Google Doc For Group Notes We’ll use stepwise (chain-of-thought–style) prompting to unpack a very complex partial differential equation into clear, audience-appropriate language without asking the AI to reveal its private reasoning. The goal is to force a structured, term-by-term explanation and surface assumptions. Note: we are purposefully using a complex example here so that we can really see the value and dangers of utilizing a LLM for environmental modeling. Model The Advection–Diffusion (or Dispersion) Equation for pollutant transport in a river: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] - \\(C\\): concentration at position \\(x\\) and time \\(t\\) - \\(D\\): diffusion coefficient (mixing) - \\(v\\): flow velocity (downstream transport) - \\(k\\): decay rate (removal) Step 1 — Your Own Explanation Write a plain-language explanation for a non-scientist audience (e.g., a community group). If you have no idea whats going on - take a guess. Go term by term and see if you can decipher whats going on. Step 2 — Baseline AI Explanation Ask an LLM for a plain-language explanation. Save the response. Baseline prompt: Explain the equation below in plain language for a non-scientist audience. \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Keep it to 6–8 sentences. Take a second here and compare your result with those at your table? Are thy identical? Step 3 — Stepwise Prompting (Structured Sections) Now force structure so the AI unpacks complexity term-by-term and surfaces assumptions. Stepwise prompt template (copy-paste) Explain the equation below using labeled sections. Do not show your internal reasoning; present only your final explanation. Sections (use headings): 1) Term-by-term meaning — explain each term in one sentence. 2) Physical interpretation — connect each term to a river process with a brief analogy. 3) Assumptions — list key modeling assumptions (e.g., dimensionality, parameter constancy, uniform mixing). 4) Units &amp; parameters — specify typical units for \\(C, D, v, k\\). 5) Edge cases — describe what happens if \\(D=0\\), \\(v=0\\), or \\(k=0\\). 6) Plain-language summary — 3 sentences for a public audience. Equation: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Step 4 — Compare &amp; Critique Clarity: Which version (baseline vs. stepwise) is clearer and why? Completeness: Did the stepwise version expose assumptions or units the baseline missed? Accuracy: Note any incorrect claims or overconfidence. Most importantly - which version did you learn something from? Step 5 — Constraint Refinement Re-prompt with tighter constraints to match a specific audience. Audience-tuning examples Policy brief style (≤150 words, 8th-grade reading level). Technical appendix style (include parameter ranges and citations placeholder). Infographic caption style (≤90 words, 3 bullets + 1 summary sentence). How did it do translating complex ideas? Extension (optional) Ask the AI to propose a simple diagram description (no image needed): axes, arrows for diffusion/advection, and a decay curve. Use this as a storyboard for a figure you might create later. "],["tutorial-getting-started-with-rstudio.html", "Appendix D Tutorial: Getting Started with RStudio D.1 1. What is RStudio? D.2 2. The RStudio Interface D.3 3. Running Code D.4 4. Projects in RStudio D.5 5. Working with Packages D.6 6. Writing and Saving Scripts D.7 7. Plotting Example", " Appendix D Tutorial: Getting Started with RStudio D.1 1. What is RStudio? R is a programming language for statistics, data analysis, and visualization. RStudio is an integrated development environment (IDE) that makes R easier to use with a friendly interface. D.2 2. The RStudio Interface When you open RStudio, you’ll usually see four main panes: Source Pane (Top-Left) Where you write and edit R scripts (.R), RMarkdown (.Rmd), or notebooks. You can run code line by line or in chunks. Console (Bottom-Left) Where R actually runs the code. You can type commands directly here for quick tests. Environment/History (Top-Right) Environment: Shows the objects (data, variables, functions) you’ve created. History: Keeps track of commands you’ve previously run. Files/Plots/Packages/Help/Viewer (Bottom-Right) Files: Navigate your project folder. Plots: Displays graphs you generate. Packages: Manage installed R packages. Help: Documentation for R functions. Viewer: Preview HTML outputs (e.g., from RMarkdown). D.3 3. Running Code Type directly into the Console and hit Enter. Or, write code in the Source Pane and: Run a single line: Ctrl + Enter (Windows) or Cmd + Enter (Mac). Run a whole script: Source button or Ctrl + Shift + Enter. D.4 4. Projects in RStudio Create a Project to keep related files together. File → New Project → New Directory (or link to an existing folder). Projects make it easier to manage code, datasets, and outputs without breaking file paths. D.5 5. Working with Packages Packages are collections of R functions, data, and documentation bundled together to extend the capabilities of base R. Think of them like “apps” you install on your phone — R comes with some built-in tools, but packages let you do much more specialized tasks. Why use packages? Packages provide extra functionality for tasks like data visualization, statistical modeling, spatial analysis, or machine learning. Where do they come from? Most packages are shared on CRAN (the Comprehensive R Archive Network), but you can also install from GitHub or other repositories. How do you use them? Install once per computer install.packages(&quot;ggplot2&quot;) Load every session (so R knows to use it) library(ggplot2) Examples of popular packages: ggplot2 → advanced graphics and plots dplyr → data wrangling and manipulation tidyr → reshaping datasets readr → reading CSV and text files shiny → building interactive web apps in R ✅ Key idea: Packages expand what R can do. Installing adds them to your computer, loading makes them available in your current session. D.6 6. Writing and Saving Scripts When you work in RStudio, you’ll often want to save your code so you can reuse it later, share it with others, or keep a record of what you did. This is where scripts come in. D.6.1 R Scripts (.R files) An R script is a plain text file that contains R code. You can write multiple lines of code and run them whenever you want, instead of typing directly into the Console. To create one: Go to File → New File → R Script (or use Ctrl + Shift + N / Cmd + Shift + N on Mac). To save: Use File → Save As... and give your file a name ending in .R. D.6.2 RMarkdown (.Rmd files) An RMarkdown file combines code, text, and output in one document. Useful for reports, homework assignments, or reproducible research. To create one: File → New File → RMarkdown You can include code chunks (inside triple backticks {r}) along with explanations in plain English. Output can be HTML, PDF, or Word documents. D.7 7. Plotting Example R makes it easy to create plots and visualize data. Plots always appear in the Plots tab (bottom-right pane in RStudio). D.7.1 Example 1: Simple Scatter Plot You can create your own vectors and plot them. # Create data x &lt;- 1:10 y &lt;- x^2 # Scatter plot plot(x, y, main = &quot;Simple Plot&quot;, xlab = &quot;x&quot;, ylab = &quot;y^2&quot;) This will generate a basic scatter plot of numbers 1–10 against their squares. D.7.2 Example 2: Using a Built-In Dataset (cars) R comes with many built-in datasets. The cars dataset contains two columns: speed → speed of cars (in mph) dist → stopping distances (in feet) We can quickly make a scatter plot to explore the relationship. # Look at the first rows of the dataset head(cars) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 # Create a scatter plot plot(cars$speed, cars$dist, main = &quot;Stopping Distance vs Speed&quot;, xlab = &quot;Speed (mph)&quot;, ylab = &quot;Stopping Distance (ft)&quot;, col = &quot;blue&quot;, pch = 19) col = “blue” makes the points blue. pch = 19 makes the points solid circles. D.7.3 Example 3: Adding a Trend Line You can add extra layers to your plots. For instance, let’s fit a simple linear model and add the regression line to the cars plot. # Fit a linear model model &lt;- lm(dist ~ speed, data = cars) # Plot again plot(cars$speed, cars$dist, main = &quot;Stopping Distance vs Speed with Trend Line&quot;, xlab = &quot;Speed (mph)&quot;, ylab = &quot;Stopping Distance (ft)&quot;, col = &quot;darkgreen&quot;, pch = 16) # Add the fitted line abline(model, col = &quot;red&quot;, lwd = 2) D.7.3.1 ggplot2 Version The ggplot2 package provides more control and produces publication-quality graphics. # Load ggplot2 library(ggplot2) # Create scatter plot with regression line ggplot(cars, aes(x = speed, y = dist)) + geom_point(color = &quot;darkgreen&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;, se = FALSE) + labs( title = &quot;Stopping Distance vs Speed with Trend Line&quot;, x = &quot;Speed (mph)&quot;, y = &quot;Stopping Distance (ft)&quot; ) ## `geom_smooth()` using formula = &#39;y ~ x&#39; ✅ Using base R, you get quick and simple plots. ✅ Using ggplot2, you get more flexible, customizable, and professional-looking plots. "]]
