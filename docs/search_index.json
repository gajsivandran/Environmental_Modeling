[["index.html", "Model Your World: Introduction to Modeling and Simulation Chapter 1 Welcome 1.1 Teaching Team Introductions Gaj Sivandran 1.2 Course Highlights 1.3 What are the learning outcomes 1.4 Notes and Textbooks 1.5 Course Topics 1.6 Classroom Etiquette 1.7 Assessment", " Model Your World: Introduction to Modeling and Simulation Gaj Sivandran 2025-10-04 Chapter 1 Welcome 1.1 Teaching Team Introductions Gaj Sivandran Teaching Interests Design (freshman and senior) Fundamental engineering (statics, fluids) Environmental labs Water resources Research Interests Climate change Active learning pedagogy Simulation modeling Decision support (socio-economic modelling) Random Facts I have an 11yr old daughter that helps me write exam questions Dogs &gt;Cats, Cricket &gt; Baseball, AFL &gt; NFL, Vegemite &gt; Peanut butter I like to run very very long distances, stilling working on why 1.2 Course Highlights This is the first offering of this course - what does that mean? Im looking for your continuous feedback on what is working and what is not Im going apply Just-In-Time teaching philosophy. What this essentially means is the course material is dynamic, if there is a need from the class to cover a topic - we can add it in Accessibility requirements for the Spring. 1.3 What are the learning outcomes By the end of the course, students will be able to: Explain the philosophy of modeling: abstraction, assumptions, and trade-offs. Use AI tools responsibly to support model design, coding, and analysis. Build and analyze basic mathematical and computational models (e.g., growth, predatorprey, carbon cycles). Implement simulation techniques in R, including discrete-event, continuous-time, and agent-based models. Explore the roles of uncertainty, sensitivity, and validation in modeling. Communicate modeling results clearly through visualizations, reports, and presentations. Class Discussion Anything you want to add/remove/emphasize/de-emphasize? Class Discussion Lets find out why you all have decided to be here. With the people around you, discuss why you are taking this class. Well share back in 5mins. Class Discussion The way we code is changing rapidly right now with the development of LLMs. You might rightly ask why do we need to know how to code? Discuss it with the people at your table We are scientists! So it would be great to see arguments from all perspectives - play devils advocate its more fun if we dont all agree What should our goal be in light of your discussion? One of my favorite education quotes: We are currently preparing students for jobs that dont yet exist using technologies that havent been invented in order to solve problems we dont even know are problems yet - Richard Riley U.S. Secretary of Education (1993-2001) 1.4 Notes and Textbooks Quick Canvas tour I am writing and publishing the textbook on the fly. To make sure you are working with the most up-to-date version hit refresh or close the tab from time to time. 1.5 Course Topics This being the first year  this is my ambitious list of topics  well see how far we get (maybe further) Introduction to Modeling  abstraction, assumptions, model types. AI &amp; Modeling Tools  using LLMs to support coding and model design. Mathematical Models  parameters, functions, growth models. Difference Equations  discrete-time dynamics, feedback, stability. Differential Equations  continuous-time systems in ecology/environment. Simulation as a Tool  discrete-event and continuous-time simulation. Uncertainty &amp; Sensitivity  calibration, robustness, validation. Spatial &amp; Agent-Based Models  individuals and space in systems. Communicating Models  visualization, ethics, limits. Capstone Showcase  final project presentations. Class Discussion Anything you want to add/remove/emphasize/de-emphasize? 1.6 Classroom Etiquette Please feel free to bring your breakfast/lunch to class  just be sure to clean up before you leave Bring whatever tech you need to take notes and engage. We will code in class so setting up R Studio is a good idea Ask questions  but please be respectful of all voices and views - wrong answers have more value than right ones! Norms - Class Discussion Lets come up with a set of rules and expectations for this class and then lets agree to follow them. 1.7 Assessment My goal with the assessments is to encourage you to put energy in the right places. I do not want to create busy work in this class. But - At the same time - sometimes having a due date forces us to do the things that are good for us, but not as much fun. Class Discussion Right now the assessment breakdown is: Homework &amp; Labs (40%)  Weekly assignments and lab reports where students build, test, and reflect on models. Final Project (40%)  Develop and present a model of a real-world environmental system (individual or group). Includes a written report and in-class presentation. Participation &amp; Preparation (20%)  In-class activities, peer feedback, and engagement in discussions. What should the project be worth? Here are the basics Milestone 1: Proposal &amp; Scoping (Week 3) Topic idea (12 paragraphs) Research question(s) Initial model concept (sketch or description) Deliverable: 12 page written proposal + brief in-class discussion Milestone 2: Background &amp; Model Design (Week 5) Short background review (12 pages, with at least 35 references) Model framework (diagram of variables, flows, assumptions) Plan for methods (what kind of model and why) Deliverable: Background report + 35 minute pitch with peer Q&amp;A Milestone 3: Prototype Model (Week 7) First working version of your model in R At least one test run with outputs 1-page reflection on challenges and next steps Deliverable: Code + reflection memo Milestone 4: Model Refinement &amp; Analysis (Week 9) Improved and more complete model Sensitivity tests, scenario comparisons, or uncertainty analysis At least 23 polished visualizations Deliverable: Draft results section (12 pages) with figures Milestone 5: Final Report &amp; Showcase (Week 10) Final written report (68 pages, including intro, methods, results, discussion, references, and code appendix) A poster of your work  well have our own digital poster session at the end of this course. Deliverable: Report + poster presentation Grading Detailed rubrics will be provided for each milestone. For Milestones 1 through 4, you will be given the opportunity to address feedback to earn back any points lost during the first submission. The project grade will be broken down as follows: Proposal &amp; Scoping: 10% Background &amp; Model Design: 15% Prototype Model: 15% Refinement &amp; Analysis: 20% Final Report &amp; Presentation: 40% Being an elective, it means you all have different levels of preparation for this course. Grades will focus on your growth rather than comparisons to other students. Admin Every Friday will be project work. Either setting the groundwork for your project or delivering a milestone. This Friday - come with a rough idea of what system youd like to model/simulate. Well use the class time to workshop the idea. There will be a graded Canvas discussion board where you will need to drop your idea into. "],["week-1-what-is-modeling.html", "Chapter 2 Week 1: What is Modeling? 2.1 What we will be doing this week 2.2 Learning Objectives 2.3 Do, Watch, Listen, Read: Student Preparation For The Week 2.4 Lets Build a Model of Learning 2.5 What Is Systems Thinking and Simulation? 2.6 Abstractionand Why Is It So Hard? 2.7 The Problem-Solving Process 2.8 Intro to Prompt Engineering", " Chapter 2 Week 1: What is Modeling? Theme: Orientation, purpose of modeling, and first steps in RStudio Goal: Set a positive tone, introduce modeling as a mindset, and start building confidence with tools like RStudio and LLMs. 2.1 What we will be doing this week Wed: Welcome, course expectations, and an introduction to modeling as a way of thinking about systems. Well define what a model is and why its useful in environmental science. Youll also begin brainstorming the systems youre most interested in. Thu: Build and sketch simple conceptual models. Well talk about abstraction, simplification, and assumptions. Youll draw your own system and explore a visual tool like LOOPY. Fri: Begin working in RStudio! Well introduce the platform, walk through a tutorial, and use an LLM to help you write your first line of R code. This day is all about taking that first steptogether. Brainstorm and team up for class projects. 2.2 Learning Objectives By the end of Week 1, students should be able to: Define what a model is and explain its purpose in environmental science. Identify abstraction, simplification, and assumptions in a given model. Sketch and describe a simple conceptual model of a natural system. Critically assess the usefulness and limitations of models. Navigate basic RStudio functions and use LLMs to scaffold a simple model script. Start to formulate your projects 2.3 Do, Watch, Listen, Read: Student Preparation For The Week 2.3.1 Download and Install RStudio Go the the following link to download RStudio RStudio Desktop Download Note: Scroll down to find windows/mac version Be sure to get RStudio - not R, RStudio includes everything you need and it creates a much easier user interface to work with Now dont worry - the expectation for this course is you have never worked with a coding language before. The purpose of this course is to offer a low stakes way to engage with coding and modeling, see its potential, and then take several other courses that focus on coding. 2.3.2 Do this tutorial Before we can explore the environmental systems we care aboutlike climate change, conservation, and sustainability, we need tools to help us think clearly and creatively. One of those tools is RStudio. Lets be honest: learning a new programming environment can feel overwhelming. Thats okay. Its normal to feel stuck, confused, or even frustrated when youre starting out. But heres the truth: We dont get to do cool science or explore new ideas without doing hard things first. This tutorial will walk you through the basics of RStudio: how it looks, how to run code, and how to get started. You dont need to master everything right awayjust take it one step at a time. Well practice together in class, and youll have support from me, your peers, and even AI tools along the way. 2.3.3 5min Read Study Confirms Climate Models are Getting Future Warming Projections Right 2.4 Lets Build a Model of Learning This is the way I see your learning. Its a simple feedback between coming to class and office hours. Activity: What Drives Learning, Enjoyment, and Science? Your First Model: A Feedback Loop The diagram youre looking at is called a systems modelspecifically, a causal loop diagram. Its the kind of model we use to: Represent complex systems using simple relationships Visualize feedback (both positive and negative) Experiment with how change flows through a system In this case, the system is about you as a learner. Whats Going On Here? Learning increases Enjoyment, which in turn increases Science. Factors can be added (green nodes) or subtracted (red nodes) from each part of the system. You can interact with the model by dragging the slider or clicking the nodes to see what happens. Task This is the first model of the courseand its about you. Your task: Play with the model: What happens when you increase the positive input? What if something subtracts from learning? As a group, add ideas to these categories: -What adds to your learning? What subtracts from your learning? Sketch your own version of the loop: What would you add to the system to help you succeed in this class? Can you identify a feedback loop (something that reinforces itself)? Whats something that could make the system spiral negatively? Wrap-up Discussion What surprised you about how small changes affected the system? How could this approach be used to model an environmental system? 2.5 What Is Systems Thinking and Simulation? Systems thinking is about seeing the world as an interconnected web of relationshipswhere change in one part of a system can ripple through others in surprising ways. Its a mindset that helps us understand the feedback loops, delays, and patterns that shape everything from ecosystems and climate to cities and communities. Simulation is how we bring those systems to life. Its the process of building simplified, dynamic representations of complex systems so we can ask questions, test scenarios, and explore what if ideaswithout needing to experiment in the real world. Simulations help us: Focus on what really matters in a system Explore how change unfolds over time Make the invisible visible Together, systems thinking and simulation allow us to understand environmental challenges more deeplyand to imagine and test solutions before we act. In this course, well use both to explore systems you care about, from forest ecosystems to climate strategies and sustainable cities. 2.6 Abstractionand Why Is It So Hard? Abstraction is the process of simplifying a complex reality by focusing only on the parts that matter most for a specific question or purpose. Its about stripping away detail so you can see the system more clearly. That might sound simplebut its not. In science (and in life), were surrounded by messy, interconnected realities. When we build a model or design a simulation, we have to decide: What do we include? What do we leave out? What assumptions are we making? Those are hard decisions. Theres no single right answer. Every abstraction involves a trade-off between realism and usability. Too simple, and the model might be useless. Too complex, and it might be impossible to understand or use. But heres why abstraction matters: Its the starting point for every scientific model, every simulation, every breakthrough idea. Abstraction helps us: Make sense of overwhelming complexity Communicate ideas clearly Focus our attention on whats driving change Build models we can analyze, test, and improve Every persons model will be different because of the unique structure and assumptions they make along the way. Thats not a problemits what makes modeling so powerful and flexible. In climate modeling for instance, they way we create projections of future climates is by taking the average response of many climate models to a expected change in forcings. Sketching Exercise A sketch is a visual model. Task: Draw a picture of a chair Share your picture with those around you What assumptions did you all make in your model Which sketch was right? 2.7 The Problem-Solving Process At the heart of modeling and simulation is a desire to solve real-world problemsquestions about climate, conservation, cities, and sustainability that dont have simple answers. To tackle those problems effectively, we need a clear and flexible process. Heres a step-by-step framework well use throughout this course: 2.7.1 Define the Problem Start by clearly stating: What system are you trying to understand or improve? What question are you trying to answer? Who is affected by this problem, and why does it matter? Example: How can we reduce the urban heat island effect in our city? 2.7.2 Simplify and Abstract No model can capture every detail. So ask: What are the key components of this system? What can we leave out (at least for now)? What assumptions are we making? This is where abstraction comes inchoosing what to keep and what to simplify so that the model is useful without being overwhelming. 2.7.3 Build a Conceptual or Mathematical Model Now sketch or code a model that represents the system: Use diagrams, equations, or simulations Identify feedbacks, delays, and influences Decide how time and change are represented This is where your system takes shape. 2.7.4 Simulate and Explore Run your model. Ask: What happens when you tweak variables? Are the results stable, surprising, or sensitive? Does this align with what you expectedor challenge it? Simulation helps us test our ideas before we act in the real world. 2.7.5 Evaluate and Refine A model is never finished. Its a tool for learning. What are the models strengths and weaknesses? How could it be improved? What new questions did it raise? Sometimes refining the problem is just as important as refining the solution. Science is often getting to the next why? 2.7.6 Communicate Even the best model wont make a difference if no one understands it. Can you explain your model clearlyvisually, verbally, or interactively? Who needs to hear this, and how should you frame it? Good science isnt just about building modelsits about sharing them. By following this process, youre not just solving technical problemsyoure learning how to think critically, collaborate effectively, and design solutions that matter. 2.8 Intro to Prompt Engineering Before we dive into RStudio, we need to learn a surprisingly powerful skill: how to talk to AI. When we use tools like ChatGPT or Copilot, the results we get depend entirely on how we frame the question. This practicedesigning questions and instructions for an AIis called prompt engineering. Good prompts: Give clear context State what youre trying to do Are specific, but not overloaded with details Might include examples or data structure Heres the difference:  Less helpful prompt: How do I R?  More helpful prompt: Im working in RStudio. I have a dataset called CO2, and I want to make a scatter plot of uptake vs. concentration. Can you show me the code? 2.8.1 Why This Matters Prompt engineering isnt just about getting the right codeits about learning how to collaborate with AI to think through problems. In this course, youll use LLMs to: Get unstuck when your code wont run Try new ideas quickly Explore how changing your prompt changes the response And just like with any tool, the more thoughtfully you use it, the better it works. Dataset Spotlight: CO Uptake in Grass Plants About the Experiment The \\(CO_2\\) dataset comes from a classic plant physiology experiment that measured how grass plants respond to different concentrations of carbon dioxide under varying conditions. Researchers wanted to understand how \\(CO_2\\) levels , plant type , and treatment (chilled vs. non-chilled) affected the rate at which plants take up carbon from the atmospherea key part of understanding photosynthesis and climate-plant interactions. Specifically, they measured \\(CO_2\\) uptake in grass plants from two groups: Quebec (cooler climate) Mississippi (warmer climate) Some plants were kept at normal temperatures, while others were chilled to simulate colder conditions. The goal was to see how these factors influenced carbon uptake at different CO concentrations. Dataset Structure This dataset includes 84 observations and 5 variables: Variable Description Plant Identifier for the individual plant (Qn or Mn, where Q = Quebec, M = Mississippi) Type Origin of the plant: \"Quebec\" or \"Mississippi\" Treatment \"chilled\" or \"nonchilled\" (i.e., whether the plant was cooled) conc CO concentration in the ambient air (in mL/L) uptake Rate of CO uptake (mol/m²/s)  this is the response variable Why Its Useful for Us This dataset is a great first modeling tool because its: Small and easy to understand Rich enough for meaningful patterns Great for visualization, group comparisons, and *basic regression modeling** A real-world example of how environmental variables interact "],["week-2-llms-and-modeling-support.html", "Chapter 3 Week 2: LLMs and Modeling Support 3.1 Learning Goals 3.2 Do, Watch, Listen, Read: Student Preparation for the Week 3.3 Introduction to LLMs in Modeling (Mon) 3.4 Capabilities and Limits of LLMs 3.5 LLMs in Environmental Modeling Workflows 3.6 Prompt Engineering for Model Development (Tue &amp; Wed) 3.7 Learning goals 3.8 Principles of effective prompts: clarity, context, constraints 3.9 Prompt types: zero-shot, few-shot, role-based (with modeling examples) 3.10 Iterative refinement and debugging prompts (the LEI loop) 3.11 ADE Prompt Library &amp; Activity 3.12 Critical Reflection: When to Use AI Tools 3.13 Reproducibility, Documentation, and Troubleshooting (Fri) 3.14 First Model - ADE", " Chapter 3 Week 2: LLMs and Modeling Support 3.1 Learning Goals By the end of this week, students should be able to: Explain what large language models (LLMs) are and how they can support simulation and coding. Apply prompt engineering techniques to improve model development. Use LLMs to reframe and clarify environmental modeling challenges. Critically evaluate when and how it is appropriate to use AI tools in science. Incorporate LLMs into workflows for reproducibility, documentation, and troubleshooting in R. 3.2 Do, Watch, Listen, Read: Student Preparation for the Week 3.2.1 Do Open an LLM tool (ChatGPT, Claude, Gemini and ask it to: Explain a simple scientific concept (e.g., greenhouse effect) in plain language. Write R code to simulate 10 years of daily temperature with a slight warming trend. Compare the outputs: What worked well? What didnt? 3.2.2 Watch: Video for Discussion Video: Master 80% of Prompt Engineering In 10 Minutes! (YouTube, 2024) Intro: This short video introduces the foundations of prompt engineering and then builds into practical strategies. It explains the core elements of a good prompt, highlights three advanced techniques, and shares a few bonus tips for refining outputs. The goal is to show how structured, intentional prompting can make AI much more useful in practiceespecially for coding, modeling, and explanation tasks. Questions to Ponder While Watching: What are the core elements of prompt design highlighted in the video? Why are they essential? Which advanced technique seems most useful for environmental modeling tasks (e.g., generating R code, simulation explanations)? How might you apply one of the bonus tips when working on your Week 2 activities? Can you think of a situation where a poorly written prompt could cause confusion or errors in scientific modeling? How would you fix it? 3.2.3 Read: Reading for Discussion Article: Reconciling the contrasting narratives on the environmental impact of large language models (Nature Scientific Reports, 2024) Intro: As we consider how to use large language models (LLMs) in environmental science, its important to recognize that these tools themselves have environmental costs. This article examines the energy use and carbon footprint of training and running LLMs, compares them with human labor, and discusses how different assumptions lead to contrasting narratives about their sustainability. Its a nuanced look at the trade-offs between the benefits of AI and the resources required to power it. Questions to Ponder While Reading: What are the main sources of environmental impact from LLMs (training vs. deployment)? How do the authors compare the impacts of LLMs to traditional human-driven approaches? Which assumptions (e.g., electricity sources, hardware lifespans) most influence the conclusions? How might these trade-offs shape your perspective on using LLMs in scientific modeling workflows? These materials will help you see both sides of using LLMs: as a tool for speeding up coding and simulation, and as a system with important limits you must understand as a scientist. 3.3 Introduction to LLMs in Modeling (Mon) Large language models (LLMs) are a new class of tools that can transform the way scientists and students approach coding, simulation, and communication. They are not replacements for human expertise, but they can act as collaboratorshelping us generate ideas, translate complex models into accessible explanations, and troubleshoot code. In this chapter, we explore what LLMs are, how they developed, and how they connect to environmental modeling workflows. 3.3.1 What Are LLMs? A large language model (LLM) is a type of artificial intelligence system trained on massive collections of text. The core idea is surprisingly simple: given a sequence of words, the model predicts the most likely next word. By stacking billions of parameters and training on billions of words, LLMs learn patterns of grammar, style, reasoning, and even coding syntax. Think of an LLM as a highly advanced autocomplete. Instead of only finishing a single word, it can continue a sentence, draft an essay, write a block of R code, or explain a scientific model in plain language. 3.3.2 A Brief History Early 2010s: Models such as word2vec and GloVe mapped words into mathematical space, capturing similarities (river is close to stream). 2017: The transformer architecture was introduced, allowing models to learn long-range patterns in text. 20182020: OpenAIs GPT-2 and GPT-3 showed that scaling up data and parameters led to dramatic improvements in fluency. 2022present: Public releases of GPT-4, Claude, Gemini, and other models made LLMs widely accessible for coding, writing, and research. This rapid evolution means todays students can use tools that did not exist even a few years ago. Discussion What do you think an appropriate use of LLMs are. Discuss with your table and lets see if we can build some community guidelines (for this class and beyond) 3.4 Capabilities and Limits of LLMs 3.4.1 Capabilities One of the reasons LLMs have gained such traction in research and education is their versatility. They are capable of generating readable text in many different styles, ranging from concise scientific summaries to conversational explanations that make technical concepts more approachable. This flexibility allows them to adapt their tone depending on the intended audience, whether it is a group of peers, policymakers, or the general public. Beyond writing, LLMs are particularly useful for producing and troubleshooting code across multiple languages, including R, Python, and MATLAB. Students working through simulations can quickly draft starter scripts, identify syntax errors, or explore alternative approaches to the same problem. In addition, LLMs can act as powerful summarization tools, condensing long articles, large datasets, or complex equations into clear, digestible insights that highlight key trends or ideas. Finally, perhaps one of their most accessible features is the ability to translate technical content into plain language, making specialized knowledge understandable to non-experts. This capacity to bridge the gap between complexity and clarity is especially valuable in environmental science, where communicating models and data to diverse audiences is critical for impact. 3.4.2 Limits Despite their impressive capabilities, LLMs come with important limitations that must be acknowledged. A well-documented issue is hallucination, where the model generates text that sounds plausible but is factually incorrect or even entirely fabricated. This can be especially problematic in scientific work, where accuracy is paramount. LLMs also reflect the biases present in their training data, which means that outputs may unintentionally reproduce stereotypes or emphasize certain perspectives while ignoring others. Another limitation is that these systems lack true reasoning or understandingthey do not know science in the way humans do, but instead predict patterns based on statistical relationships in text. This means their explanations can oversimplify concepts or miss critical assumptions. Finally, there are reproducibility challenges, since the same prompt can yield slightly different outputs depending on the model and context, making it harder to standardize results for scientific workflows. Recognizing these limits helps ensure that we use LLMs critically, as aids to human reasoning rather than substitutes for it. Reflection Prompt Think about a task in environmental modeling youve worked on recently (coding, data analysis, or communicating results). Which of the capabilities described here could have supported your work? Which limitations would you need to watch out for? How might you balance the efficiency of using an LLM with the need for accuracy and scientific rigor? 3.5 LLMs in Environmental Modeling Workflows How do LLMs connect to the practice of environmental modeling? Their utility lies not in replacing the scientist, but in serving as a flexible assistant at different stages of the workflow. One of the most immediate applications is code generation. For instance, a student working on a logistic population growth model in R can prompt an LLM to draft the basic script. Even if the generated code is not perfect, it provides a working foundation that can be edited and refined, reducing the time spent on tedious setup. Similarly, LLMs can assist with documentation support. In RMarkdown or other coding environments, clear documentation is essential for reproducibility, yet students often overlook it. By asking an LLM to add explanatory comments, create section headers, or translate code into step-by-step descriptions, the workflow becomes easier to follow both for the original author and for future collaborators. Another important use is simulation explanation. Equations that may appear abstract to non-specialistssuch as those describing exponential growth, diffusion, or temperature responsecan be reframed by an LLM into accessible narratives. For example, the logistic growth equation can be explained as a story of a population that grows quickly at first but slows as resources become scarce, eventually leveling off at a carrying capacity. These applications highlight the potential of LLMs to streamline scientific work: they can help students start coding more quickly, reduce frustration by catching errors or filling in gaps, and make models more communicable to a wider audience. At the same time, none of these tasks can be fully delegated without oversight. Generated code must be tested for accuracy, documentation must be checked for completeness, and plain-language explanations must be reviewed to ensure they do not omit critical assumptions. In this way, LLMs become collaborative tools that support efficiency and clarity while keeping the responsibility for scientific rigor firmly in human hands. Activity: Explain a Complex Model with Stepwise Prompting Well use stepwise (chain-of-thoughtstyle) prompting to unpack a very complex partial differential equation into clear, audience-appropriate language without asking the AI to reveal its private reasoning. The goal is to force a structured, term-by-term explanation and surface assumptions. Note: we are purposefully using a complex example here so that we can really see the value and dangers of utilizing a LLM for environmental modeling. Model The AdvectionDiffusion (or Dispersion) Equation for pollutant transport in a river: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] - \\(C\\): concentration at position \\(x\\) and time \\(t\\) - \\(D\\): diffusion coefficient (mixing) - \\(v\\): flow velocity (downstream transport) - \\(k\\): decay rate (removal) Step 1  Your Own Explanation Write a plain-language explanation for a non-scientist audience (e.g., a community group). If you have no idea whats going on - take a guess. Go term by term and see if you can decipher whats going on. Step 2  Baseline AI Explanation Ask an LLM for a plain-language explanation. Save the response. Baseline prompt: Explain the equation below in plain language for a non-scientist audience. \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Keep it to 68 sentences. Take a second here and compare your result with those at your table? Are thy idenitical? Step 3  Stepwise Prompting (Structured Sections) Now force structure so the AI unpacks complexity term-by-term and surfaces assumptions. Stepwise prompt template (copy-paste) Explain the equation below using labeled sections. Do not show your internal reasoning; present only your final explanation. Sections (use headings): 1) Term-by-term meaning  explain each term in one sentence. 2) Physical interpretation  connect each term to a river process with a brief analogy. 3) Assumptions  list key modeling assumptions (e.g., dimensionality, parameter constancy, uniform mixing). 4) Units &amp; parameters  specify typical units for \\(C, D, v, k\\). 5) Edge cases  describe what happens if \\(D=0\\), \\(v=0\\), or \\(k=0\\). 6) Plain-language summary  3 sentences for a public audience. Equation: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Step 4  Compare &amp; Critique Clarity: Which version (baseline vs. stepwise) is clearer and why? Completeness: Did the stepwise version expose assumptions or units the baseline missed? Accuracy: Note any incorrect claims or overconfidence. Most importantly - which version did you learn something from? Step 5  Constraint Refinement Re-prompt with tighter constraints to match a specific audience. Audience-tuning examples Policy brief style (150 words, 8th-grade reading level). Technical appendix style (include parameter ranges and citations placeholder). Infographic caption style (90 words, 3 bullets + 1 summary sentence). Step 6  Mini-Deliverable Submit: (1) your own explanation, (2) baseline AI output, (3) stepwise output, (4) a 35 bullet critique comparing them, and (5) one audience-tuned version. Extension (optional) Ask the AI to propose a simple diagram description (no image needed): axes, arrows for diffusion/advection, and a decay cue. Use this as a storyboard for a figure you might create later. 3.6 Prompt Engineering for Model Development (Tue &amp; Wed) Principles of effective prompts: clarity, context, constraints. Prompt types: zero-shot, few-shot, role-based prompts. Iterative refinement and debugging prompts. Activity: Students write and test prompts for generating R code to simulate temperature data. 3.7 Learning goals By the end of today, students will be able to: - craft clear, contextualized, and constrained prompts that produce correct code and documentation; - select and combine zero-shot, few-shot, and role-based prompts for modeling tasks; - iteratively refine outputs using structured critique, unit tests, and debugging prompts; - apply these skills to build and explain a simple advectiondiffusiondecay (ADE) model in R. 3.8 Principles of effective prompts: clarity, context, constraints Clarity (goal + audience): State the task and who it is for. Write R code for first-year environmental science students. Context (problem + assumptions): Include the equation, domain, units, and assumptions. 1-D ADE, L = 10 km, v = 0.2 m/s, D = 10 m²/s, k = 1e-5 s¹, Dirichlet at x = 0, Neumann at x = L. Constraints (format + checks): Specify interfaces, style, tests, plots, and failure modes. Return a function run_ade(params); add a CFL check; produce one line plot and one time-series plot; comment every major step. Success criteria: Tell the model how you will judge success. Code must run without additional packages beyond ggplot2 and dplyr. Prompt template ASK: &lt;what to build/explain&gt; CONTEXT: &lt;equations, domain, units, assumptions&gt; CONSTRAINTS: &lt;APIs, style, allowed packages, runtime, plots&gt; CHECKS: &lt;tests/diagnostics to include&gt; OUTPUT FORMAT: &lt;function name, file structure, markdown section, etc.&gt; AUDIENCE: &lt;novice, advanced, instructor notes&gt; 3.9 Prompt types: zero-shot, few-shot, role-based (with modeling examples) Zero-shot  no examples, just a precise specifiction (spec) Implement a CrankNicolson diffusion step and 1st-order upwind advection for the 1-D ADE; include a CFL diagnostic and return a tibble of (time_h, x, C). Few-shot  show a small, high-quality example to anchor style/format. Provide a short example of a function signature and one test, then ask for an analogous function for ADE. Role-based  assign the model a persona to set expectations and tone. You are a hydrology TA. Produce commented, teachable R code and insert two discussion questions that probe assumptions. When to mix: Start role-based + zero-shot to draft; add few-shot when you need consistent structure (e.g., identical plotting themes across labs). 3.10 Iterative refinement and debugging prompts (the LEI loop) L  Launch a first draft with strict constraints. E  Evaluate using tests, plots, and quick sanity checks (mass balance, units, stability numbers). I  Iterate with targeted prompts: Examples: Diagnose: Why does concentration become negative near the boundary? Propose two fixes and implement the safer one. Add input validation: stop with a clear message when CFL &gt; 0.9 or when D &lt; 0. Refactor into setup_grid(), step_CN(), step_advect(), apply_decay(). Return a named list. Generate three unit tests using testthat for: CFL computation, Neumann boundary, non-negative concentration. Write a 5-line docstring explaining assumptions and limitations for non-experts. 3.11 ADE Prompt Library &amp; Activity Our goal is to build and explain a simple AdvectionDiffusion (ADE) model in class using careful prompts and iterative refinement. 3.11.1 What youll build (at a glance) An R function run_ade(params) that simulates \\[ \\frac{\\partial C}{\\partial t} \\;=\\; D\\,\\frac{\\partial^2 C}{\\partial x^2} \\;-\\; v\\,\\frac{\\partial C}{\\partial x} \\;-\\; k\\,C \\] on \\([0,L]\\) with Dirichlet at \\(x=0\\) and zero-gradient (Neumann) at \\(x=L\\). Built-in checks for CFL and diffusion number \\(r_D\\). Two plots: (i) spatial profiles at selected times, (ii) time series at stations. Short, plain-language documentation of assumptions and limitations. 3.11.2 Spec  Code Write an R function run_ade(params) that simulates the 1-D advectiondiffusion equation \\[ \\frac{\\partial C}{\\partial t} = D\\,\\frac{\\partial^2 C}{\\partial x^2} - v\\,\\frac{\\partial C}{\\partial x} - k\\,C \\] on the domain \\([0, L]\\) with Dirichlet at \\(x=0\\) and zero-gradient (Neumann) at \\(x=L\\). Include: a CFL check, diffusion number \\(r_D\\), two plots (profiles and station time-series), and comments suitable for first-year students. 3.11.2.1 Explain assumptions In 5 bullets, state modeling assumptions (dimensionality, parameter constancy, mixing, linear decay) and one situation where each assumption breaks. 3.11.2.2 Stability &amp; units Add a helper diagnostics() that prints CFL, Péclet, and a units table (C in mg/L, v in m/s, D in m²/s, k in 1/s). Warn when CFL &gt; 0.9. 3.11.2.3 Visualization Plot profiles at \\(t=\\) 0, 1, 3, 6 h and time-series at \\(x=\\) 1, 5, 9 km. Use clear axis labels and a legend; keep plotting code under 20 lines. In-class group activity (4550 min): Prompt  Plan  Build  Verify Uses chain-of-thought prompting safely by asking the model to output a plan (step list/pseudocode) before code. Deliverables: prompt(s), plan, R script, two plots, short reflection. 3.11.2.4 Common pitfalls &amp; how to prompt around them Vague goals  meandering code  Limit the solution to one function run_ade;  80 lines; include two plots and a diagnostics print. Hidden assumptions  List all assumptions you made; mark each as required or replaceable. Boundary errors  Explain, in words, how you implement Dirichlet at \\(x=0\\) and zero-gradient at \\(x=L\\); then show the exact index operations. Numerical instability  Compute and print CFL and \\(r_D\\); if CFL &gt; 0.9, automatically shrink dt and state the new value. Over-fancy output  No external packages beyond ggplot2/dplyr; avoid themes; keep defaults. 3.12 Critical Reflection: When to Use AI Tools Deciding when to use an LLM is not always straightforward. These tools offer powerful benefits but also come with risks and ethical concerns. As environmental scientists, we need to think critically about how AI fits into our workflows and how it might affect the quality, accessibility, and trustworthiness of science. 3.12.1 Benefits LLMs can accelerate many parts of the research process. They provide speed, helping draft code, summaries, or explanations in seconds. They also increase accessibility, lowering the entry barrier for students or collaborators who may not yet have advanced coding or writing skills. LLMs often spark creativity, generating new ways of framing a problem or suggesting approaches we might not have considered. Finally, they offer support for non-experts: a student new to modeling can use an LLM to explain equations or code in plain language, building confidence and understanding more quickly. 3.12.2 Risks and Limits At the same time, AI-generated content comes with important limitations. The most pressing concern is accuracy: LLMs can produce convincing but incorrect answers. This problem, often called hallucination, makes it dangerous to rely on AI outputs without verification. Models also inherit biases from their training data, which can shape the tone, assumptions, or inclusivity of their responses. There are also ethical concerns, including the environmental cost of training large models, the potential for plagiarism or misuse, and broader questions about authorship and credit in scientific work. Recognizing these risks is essential for responsible use. 3.12.3 Guidelines for Responsible Use in Environmental Science To make AI a constructive tool rather than a crutch, we can follow a few guidelines: Use AI to support, not replace, expertise. Treat LLMs as collaborators that generate drafts, not as authorities. Verify and validate outputs. Always test AI-generated code and fact-check explanations. Document when AI was used. Transparency helps others understand how results were created. Consider the audience. Decide whether an AI-generated explanation is appropriate for a scientific paper, a classroom activity, or public communication. Reflect on ethics. Think about sustainability, fairness, and responsible authorship when integrating AI into research. Debate  Should We Use AI in Research? Divide into groups. Half the class argues for using LLMs in environmental research, and half argues against. Use examples from your own experience and the guidelines above. After the debate, reflect as a group: Which arguments were most persuasive? What conditions or safeguards make AI use acceptable? Where should we draw the line between helpful assistance and over-reliance? 3.13 Reproducibility, Documentation, and Troubleshooting (Fri) Using LLMs to improve reproducibility: RMarkdown templates, commenting code, documenting decisions. Hands-on: Simulate a simple temperature model in R (linear warming trend + random noise). Use LLMs for: - Suggesting code improvements. - Adding explanations and comments. - Identifying potential reproducibility pitfalls. Reflection: How does AI support or hinder scientific reproducibility? 3.14 First Model - ADE The advectiondiffusion equation (ADE) is a fundamental tool in environmental science for describing how substances such as pollutants, heat, or nutrients move and transform in natural systems. It combines three processes  advection (transport by bulk flow), diffusion (spreading due to mixing or molecular motion), and decay (loss by reaction, degradation, or uptake). Together, these processes govern how concentrations change in space and time. 3.14.1 General Form In one spatial dimension, the ADE is written as: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] where: - \\(C(x,t)\\) = concentration of the substance at location \\(x\\) and time \\(t\\) - \\(D\\) = diffusion (or dispersion) coefficient \\((\\text{L}^2/\\text{T})\\) - \\(v\\) = advective velocity (bulk flow speed, \\(\\text{L}/\\text{T}\\)) - \\(k\\) = decay rate constant \\((1/\\text{T})\\) This is a partial differential equation (PDE) because it describes how concentration changes both with respect to time (\\(t\\)) and space (\\(x\\)). 3.14.2 Term-by-Term Meaning Diffusion Term \\((D \\frac{\\partial^2 C}{\\partial x^2})\\): Captures the natural tendency of a substance to spread out, whether through molecular diffusion (random particle motion) or turbulent mixing. In rivers, this reflects how pollutants disperse laterally and longitudinally. Advection Term \\((-v \\frac{\\partial C}{\\partial x})\\): Represents bulk transport due to flow. In a river, advection moves pollutants downstream at approximately the mean flow velocity. Decay Term \\((-kC)\\): Accounts for processes that remove the substance over time. Examples include radioactive decay, microbial degradation of organic matter, or chemical reactions that break down contaminants. 3.14.3 Assumptions Behind the ADE Like all models, the ADE relies on simplifying assumptions: 1. Homogeneity of parameters: \\(D\\), \\(v\\), and \\(k\\) are assumed constant in space and time. 2. One-dimensional flow: The river or system is treated as a single streamline, ignoring lateral and vertical variation. 3. Continuum assumption: Concentration is treated as a smooth, continuous field rather than individual particles. 4. Linear processes: Each term acts independently and linearly, with no feedbacks or nonlinear effects. These assumptions make the equation mathematically tractable, but real systems often require adjustments or numerical solutions to capture complexity. 3.14.4 Applications in Environmental Science Rivers and Streams: Tracking the downstream fate of pollutants (e.g., nutrients, heavy metals, thermal plumes). Atmosphere: Modeling dispersion of air pollutants under wind flow and turbulent mixing. Groundwater: Describing contaminant transport through porous media. Oceans and Lakes: Simulating nutrient plumes or thermal pollution. In each case, the relative importance of advection, diffusion, and decay depends on system parameters. A fast river with low diffusion behaves differently than a stagnant pond with strong decay. 3.14.5 Analytical Solutions For simple cases, the ADE has analytical solutions. A classic example is the instantaneous point source (a sudden spill at \\(x=0\\), \\(t=0\\)) in an infinite domain: \\[ C(x,t) = \\frac{M}{\\sqrt{4\\pi D t}} \\exp \\left( -\\frac{(x - vt)^2}{4Dt} - kt \\right) \\] where \\(M\\) is the mass released. This solution shows a Gaussian plume that spreads (due to diffusion), shifts downstream (due to advection), and decreases in height (due to decay). 3.14.6 Numerical Solutions For realistic boundary conditions (finite rivers, variable flows), numerical methods such as finite difference, finite element, or particle tracking are used. These methods discretize space and time, approximating how concentration evolves step by step. 3.14.7 Key Dimensionless Numbers Two ratios help characterize transport: Péclet Number (\\(Pe\\)): \\[ Pe = \\frac{vL}{D} \\] Ratio of advection to diffusion. High \\(Pe\\) means transport is dominated by flow. Damköhler Number (\\(Da\\)): \\[ Da = \\frac{kL}{v} \\] Ratio of reaction/decay to advection. High \\(Da\\) means rapid decay compared to transport. Together, \\(Pe\\) and \\(Da\\) guide whether a pollutant plume will spread, persist, or disappear quickly. 3.14.8 Visualization Low velocity, high diffusion: plume spreads symmetrically around the release point. High velocity, low diffusion: plume moves downstream as a narrow band. Strong decay: plume shrinks and may vanish before traveling far. 3.14.9 Reflection Questions Which term (advection, diffusion, or decay) dominates in a fast-flowing river vs. a still pond? How does increasing \\(D\\) change the shape of a pollution plume? What are the consequences of assuming one-dimensional flow when rivers have significant lateral mixing? How might climate change (altered flow velocities, higher temperatures) affect ADE parameters? "],["week-3-mathematical-models-parameters-functions-and-growth.html", "Chapter 4 Week 3: Mathematical Models  Parameters, Functions, and Growth 4.1 Introduction 4.2 Components of a Mathematical Model 4.3 Types of Mathematical Models 4.4 Growth Models 4.5 Parameters in Growth Models 4.6 Fitting Models to Data", " Chapter 4 Week 3: Mathematical Models  Parameters, Functions, and Growth 4.1 Introduction Mathematical models are purposeful simplifications of real-world systems. They distill complex environmental processeslike population change, heat transfer, carbon cycling, or pollutant transportinto a small set of variables, parameters, and rules. By translating mechanisms into equations or algorithms, models help us forecast likely futures, analyze drivers and feedbacks, and make decisions when data are limited or stakes are high. A good model balances clarity and realism. It should be simple enough to understand and compute, yet detailed enough to capture the processes that matter for the question at hand. Importantly, every model is conditional: its outputs reflect its assumptions, inputs, and uncertainties. Rather than delivering truth, models provide structured what-ifsevidence-based scenarios that inform conservation planning, risk assessment, and policy. In this chapter we will: Name the parts of a model (variables, parameters, functions, initial/boundary conditions) and explain what each does. Compare growth forms (linear, exponential, logistic, decay, thresholds) and match them to ecological stories. Fit models to data and interpret parameters (e.g., growth rate \\(r\\), carrying capacity \\(K\\)) with attention to error and uncertainty. Test end-cases and sensitivity to identify which assumptions/parameters drive outcomes. Connect to decisions, using scenarios to explore management options and communicate uncertainty clearly. By the end, you should be able to look at an environmental problem, choose an appropriate model form, justify its assumptions, estimate its key parameters, and use it responsibly to support real-world decisions. 4.1.1 What is a Mathematical Model? A mathematical model is a framework that encodes assumptions about how a system changes using symbols, functions, and relationships. Within a model, variables represent system states that change over time or space, such as population size \\(P(t)\\), pollutant concentration \\(C(x,t)\\), or temperature \\(T(t)\\). These variables are influenced by parameters, which are fixed values that shape system behaviorfor example, the growth rate \\(r\\), the decay constant \\(\\lambda\\), or the carrying capacity \\(K\\). To anchor the model, we specify initial conditions that describe the system at the starting point (e.g., \\(P(0) = P_0\\)) and boundary conditions that define how the system interacts with its environment, such as pollutant inputs at the upstream end of a river. The dynamics of the system are then expressed through equations, whether algebraic, difference, or differential, that link variables and parameters together. Depending on the purpose and data available, models can take many forms: mechanistic or physically based models grounded in process understanding, statistically based models built from data patterns, probability-based models that capture randomness, or hybrids that combine multiple approaches. 4.1.2 Why Models Matter in Environmental Science Environmental systems are complex, operate across multiple scales, and are often studied with limited or imperfect data. Because of this, intuition alone is rarely enough to guide effective decision-making. Mathematical models provide a structured way to translate ecological processes, observations, and hypotheses into a form that can be tested, refined, and applied. They act as a bridge between raw data and actionable insight. Models help us to: Explain assumptions about processes. For example, a snowmelt model can explicitly represent how warming temperatures drive runoff timing, making clear what processes are assumed to matter most. Forecast future states under different scenarios. With population models, we can project whether an endangered species will recover or decline under various management strategies. Diagnose key drivers and feedbacks. Climate-carbon cycle models, for instance, allow us to separate the influence of emissions, land-use change, and natural sinks in shaping atmospheric CO levels. Design &amp; Manage interventions. Harvest models can reveal what fishing quotas are sustainable, while restoration models can test whether habitat improvements are sufficient to support species recovery. Quantify uncertainty and communicate confidence. No prediction is perfect, but models allow us to show a range of outcomeshelping managers and policymakers make informed decisions even when data are limited. Decision Contexts Regulation: Will pollutant concentrations in a river exceed safe drinking-water thresholds under typical or extreme flow conditions? Conservation: What harvest rate or protected-area size will keep a fish population near its target biomass while still allowing human use? Climate adaptation: How might different greenhouse gas emissions scenarios affect the number of extreme-heat days in a city, and what does this imply for public health planning? Restoration: If wetlands are reconnected to a floodplain, how long will it take for bird populations to rebound, and what level of uncertainty surrounds that estimate? In short, models matter because they provide a laboratory for ideasa place where scientists and decision-makers can explore what if questions, test assumptions, and evaluate possible futures before they unfold in the real world. 4.1.3 The Balance Between Simplification and Realism When building a mathematical model, one of the most important choices is how much detail to include. Every model is a simplification of reality, but the degree of simplification can make the difference between a model that is clear and useful, and one that is either too crude to be informative or too complicated to be tractable. Simplification benefits Simplified models strip away many of the messy details of real-world systems in order to focus on core dynamics. Because they involve fewer parameters, they are easier to build with limited data, faster to compute, and easier to explain to diverse audiences. For instance, an exponential growth equation can help illustrate why invasive species may spread rapidly, even if it does not capture every factor influencing their establishment. Realism benefits More realistic models incorporate mechanisms, thresholds, or feedbacks that can matter in specific contexts. They may include spatial variation, seasonality, or nonlinear processes that strongly affect system outcomes. Realistic models can therefore give more accurate predictions for particular systems, especially when management or policy depends on fine-scale details. Trade-offs Every choice involves a trade-off. A model that is too simple risks underfittingfailing to capture critical dynamics. A model that is too complex risks overfittingmatching noise in the data rather than true processes. More detailed models also require more data and can be more sensitive to parameter uncertainty. Striking the right balance means aligning the model with the purpose: is it meant for teaching a concept, exploring scenarios broadly, or providing site-specific policy advice? Example. Consider modeling the population of salmon in a river system. A simplified logistic growth model may capture the overall idea that the population grows quickly at first and then levels off at a carrying capacity due to limited habitat. This is useful for teaching and for exploring general harvest rules. But for management decisions about a particular salmon run, a more realistic model may be neededone that accounts for age structure, seasonal migration, water temperature, and spawning habitat availability. The simple model is easier to communicate and requires fewer data, while the realistic model is harder to build but can give more reliable forecasts for that river system. Common Pitfalls Treating model outputs as absolute facts instead of scenario-conditioned projections. Adding unnecessary complexity that the data cannot support. Ignoring uncertainty in parameters, model structure, or future scenarios, which can lead to misplaced confidence in results. In practice, good modelers acknowledge these trade-offs openly and design models that are as simple as possible, but not simpler for the problem at hand. 4.1.4 Example: Population Growth Population growth is one of the most fundamental processes in ecology, and models of growth have been central to understanding species invasions, conservation, and sustainable harvest management. Two of the most widely used forms are the exponential and logistic models. Exponential model \\[ P(t) = P_0 e^{rt} \\] In this model, the rate of change is proportional to the current population size. This leads to accelerating growth: the larger the population gets, the faster it increases. Ecological interpretation: Exponential growth captures the early stages of colonization or invasion, when resources are abundant and limiting factors such as predation or competition are minimal. Parameter: The intrinsic growth rate \\(r\\) determines how rapidly the population increases. The doubling time is given by \\[ t_d = \\frac{\\ln 2}{r}, \\] meaning populations with larger \\(r\\) double in size much faster. Logistic model \\[ P(t) = \\frac{K}{1 + A e^{-rt}}, \\quad A=\\frac{K-P_0}{P_0}. \\] The logistic model modifies exponential growth by adding a carrying capacity \\(K\\), representing the maximum sustainable population size given environmental limits such as food, space, or habitat quality. Initial condition: \\(P(0) = P_0\\). Dynamics: Growth is initially fast (similar to exponential growth), but slows as resources become limited. Eventually, the population levels off near \\(K\\), producing an S-shaped (sigmoid) curve. Insights Population dynamics are sensitive to small changes in parameters. For example, a slightly higher \\(r\\) may cause a species to reach \\(K\\) much faster, while changes in \\(K\\) shift the long-term ceiling. The logistic form highlights the role of feedbacks: the growth rate effectively decreases as population size increases. These models are directly applicable to conservation and harvest decisions, helping managers set quotas, predict recovery times, or evaluate the risk of extinction. Illustrative example. Imagine an invasive mussel species introduced into a new lake. At first, the population grows nearly exponentiallyfood is plentiful and there are no natural predatorsso the number of mussels doubles every few months. However, as the population expands, food resources become depleted and available habitat fills. At this point, exponential growth overestimates reality, and the logistic model provides a better description: growth slows and the population stabilizes around a carrying capacity determined by the lakes productivity. Conversely, in conservation contexts, a logistic model can help predict recovery. Suppose a fish population in a marine reserve is protected from harvest. The logistic model allows managers to estimate how long it will take the population to rebuild to near carrying capacity, and to test different scenarios (e.g., reopening harvest at different times). These insights show how relatively simple growth models can guide real-world environmental decisions. 4.1.5 The Modeling Cycle Define the scientific or decision question. Identify variables, processes, and scales. Choose model type and specify equations, ICs, and BCs. Estimate parameters from literature or data. Calibrate to part of the data and validate with another. Analyze sensitivity and uncertainty. Run scenarios to inform decisions. Iterate as new data or insights emerge. Models are rarely completed. The modeling development cycle results in updates to the model each iteration. Trying to produce a perfect model the first time through the cycle is not the goal. We learn with every development cycle, so we teh goal is always to get to a testable workable model, run it, test it, rethink it, improve it and repeat. 4.1.6 Choosing the Right Level of Detail A central challenge in modeling is deciding how much detail is enough. Every model is an abstraction of reality, but the level of abstraction should be tailored to the problem being addressed. Too simple, and the model may miss key dynamics; too complex, and it may become impossible to calibrate, explain, or use in decision-making. Match complexity to purpose The right level of detail depends on what the model is meant to achieve. For teaching or communication, simple models are often best. An exponential or logistic growth model can clearly illustrate fundamental ideas like compounding growth or resource limits without overwhelming the learner. For policy or regulation, more detail is often necessary. A government agency setting water-quality standards might need a physically based pollutant transport model that accounts for river flow, sediment interactions, and decay rates. Match complexity to data availability A model is only as good as the data available to support it. Overly detailed models with many parameters may look realistic but are prone to overparameterization, fitting noise instead of signal, if the necessary data are sparse or uncertain. For example, if only basic annual counts of a fish population are available, a logistic growth model may be the best fit. Trying to build an age-structured model with dozens of parameters would not be justified without high-resolution demographic data. Match complexity to computation needs The practical use of a model also depends on how much time and computational power is available. When running thousands of simulations for scenario testing or sensitivity analysis, simpler models (e.g., reduced-form climate models) may be preferable. More complex models (e.g., coupled climatecarbon cycle simulations) may provide greater realism but are too slow to be run repeatedly in real time. Example. Consider modeling coastal flooding risk. A simple model might assume a uniform sea-level rise plus storm surge probability to give a quick estimate of risk for city planning workshops. A more detailed model might incorporate high-resolution topography, tidesurge interactions, and climate projections for use in designing levees or evacuation plans. Both models serve important roles, but their usefulness depends on contextwhat decisions are being made, what data exist, and how quickly results are needed. In practice, good modeling involves finding the sweet spot where the model is complex enough to capture the essential dynamics but simple enough to be applied, tested, and communicated effectively. 4.1.7 Summary Mathematical models are simplified yet powerful tools that help us connect environmental processes to mathematical structures. They provide a way to translate complexity into variables, parameters, and equations that can be analyzed, tested, and applied to real-world decisions. Good models balance simplicitywhich aids clarity, computation, and communicationwith realism, which improves accuracy and relevance for specific contexts. Models matter because they allow us to explain processes, forecast future states, diagnose key drivers, design management strategies, and quantify uncertainty. They are not absolute truths but structured what-if experiments that reveal how assumptions and inputs shape outcomes. Examples such as population growth show how different model structures tell different ecological stories: exponential growth captures early invasions, while logistic growth highlights resource limits and feedbacks. Other examples, like climatecarbon models or pollutant transport equations, illustrate how models can range from very simple to highly detailed, depending on the purpose, data availability, and computational needs. Ultimately, the art of modeling lies in choosing the right level of detailcomplex enough to capture the dynamics that matter, but simple enough to remain tractable and interpretable. When used thoughtfully, models serve as both conceptual laboratories for testing ideas and practical tools for guiding conservation, regulation, and climate adaptation decisions. 4.2 Components of a Mathematical Model Every mathematical model is built from a common set of ingredients. These componentsvariables, parameters, functions, initial conditions, and boundary conditionsdefine what the model represents, how it behaves, and how we interpret its results. Understanding these pieces is essential before moving on to growth models or more advanced formulations. 4.2.1 Variables Variables are the quantities in a model that can change. They capture the dynamic aspects of a system. Independent variables are inputs that we control or that act as the clock or map of the system. Time is the most common independent variable, but space (location along a river, depth in a lake, elevation on a mountain) often serves the same role. Dependent variables are the outputs that depend on the independent variables. For instance, population size depends on time, dissolved oxygen concentration depends on depth, and temperature depends on both latitude and elevation. In notation, we usually write dependent variables as functions of independent ones: \\[ P(t) \\quad \\text{population size over time}, \\qquad C(x,t) \\quad \\text{pollutant concentration in space and time}. \\] 4.2.2 Parameters Parameters are fixed values that influence how the system behaves. Unlike variables, they are usually assumed to remain constant during the simulation of a model, but they strongly shape its outcomes. Growth rate (\\(r\\)) determines how fast a population or process increases. Carrying capacity (\\(K\\)) sets the maximum sustainable population size in a logistic model. Decay constant (\\(\\lambda\\)) defines the speed of exponential decay, such as how quickly pollutants break down or isotopes lose radioactivity. Parameters are often unknown and must be estimated from data, experiments, or literature. Changing parameter values can drastically alter model behavior, which makes sensitivity analysis a crucial step in modeling. Example. Radiocarbon dating relies on the fact that carbon-14 decays at a fixed rate. The decay constant \\(\\lambda\\) gives the half-life of the isotope and allows us to estimate the age of archaeological samples. Do parameters always stay constant? Not necessarily. While many models assume fixed parameters for simplicity, parameters can themselves vary through time or depend on environmental conditions: A fish populations growth rate (\\(r\\)) might drop during drought years when food is scarce. The carrying capacity (\\(K\\)) of a wetland may shift seasonally as water levels rise and fall. The decay constant (\\(\\lambda\\)) for a pollutant could change with temperature or pH. When parameters vary during a simulation, the model becomes more realistic but also more complex. These cases often require functions (e.g., \\(K(t)\\), \\(r(T)\\)) instead of constants, which better reflect dynamic environmental conditions. This introduces an important modeling choice: keep parameters constant for tractability, or allow them to vary to capture richer system behavior. 4.2.3 Functions Functions define the mathematical relationship between inputs (independent variables) and outputs (dependent variables). They are the backbone of a model, expressing how change happens. Deterministic functions produce the same output every time for a given input (e.g., a logistic growth equation). Stochastic functions include randomness, producing different outputs each time even with the same inputs (e.g., rainfall arrival modeled as a random process). Linear functions imply proportionality, such as a young trees height increasing linearly with age. Nonlinear functions capture thresholds, feedbacks, or saturation effects, such as logistic population growth leveling off at a carrying capacity. Example. A tree might grow roughly linearly in height during its early years but eventually slow as it approaches a biological maximum, a shift that requires a nonlinear model to represent correctly. 4.2.4 Initial Conditions Initial conditions specify the starting state of the system. Without them, many equations have infinitely many possible solutions, so they are essential for uniqueness. Purpose. They anchor the model at time zero. Examples. \\(P(0)=100\\): a salmon population of 100 individuals at the beginning of the study. \\(C(x,0)=0\\): no pollutant present in the river at the start. Changing the initial condition can dramatically alter system outcomes, especially in nonlinear systems. For example, a small population may fail to establish due to demographic stochasticity, while a slightly larger one might grow to carrying capacity. 4.2.5 Boundary Conditions Boundary conditions describe what happens at the edges of the system in space or time. They are critical when we model processes that unfold in rivers, landscapes, or the atmosphere, because what happens at the boundaries influences the interior. Dirichlet conditions fix the value at a boundary (e.g., the pollutant concentration at the upstream end of a river is set by an industrial discharge). Neumann conditions fix the rate of change or flux at a boundary (e.g., no heat flow across an insulated wall). Mixed conditions combine aspects of both (e.g., pollutant concentration at a boundary depends partly on inflow and partly on exchange with the environment). Example. In modeling stream pollution, we might set a Dirichlet condition at the upstream boundary to represent the known concentration coming in from a factory, and a Neumann condition at the downstream end to represent no net flux leaving the system beyond the reach of interest. Boundary and initial conditions together ensure that the mathematical problem is well-posed, meaning that the model has a unique and physically meaningful solution. 4.3 Types of Mathematical Models Mathematical models can be grouped in different ways depending on how they are constructed, what assumptions they make, and what role they serve. In environmental science, it is especially useful to distinguish between conceptual, empirical, mechanistic, physically based, statistically based, probability-based, and discrete/continuous models. Each of these types has strengths, limitations, and contexts where they are most useful. 4.3.1 Conceptual Models Conceptual models are qualitative representations of systems. Rather than focusing on detailed equations or precise numerical predictions, they capture the structure of a systemits main components and how they are connected. Format. Conceptual models often take the form of flow diagrams, influence charts, or causal loop diagrams. These visual tools show arrows linking drivers, processes, and outcomes, emphasizing relationships rather than calculations. Purpose. The goal is to build a shared mental map of the system, clarify assumptions, and decide which processes are most important to represent. By stripping away complexity, conceptual models help teams focus on the big picture. Strengths. They are simple, intuitive, and accessible to diverse audiences, making them powerful tools for communication, brainstorming, and scoping before moving into quantitative modeling. Limitations. Because they lack equations and numbers, conceptual models cannot generate predictions or quantify uncertainty. They are best viewed as a starting point, not an end product. Example. A watershed conceptual model might show precipitation leading to runoff, infiltration, groundwater recharge, and river flow, without specifying the mathematical relationships. Such a diagram makes clear that rainfall drives multiple pathways of water movement, and that groundwater recharge links surface and subsurface systems. This helps scientists, managers, and stakeholders agree on what processes matter before investing in a quantitative hydrological model. Broader use. Conceptual models are widely applied in ecology and environmental science. For example: In conservation planning, a conceptual model might link habitat loss, predator pressure, and food availability to species survival. In climate science, diagrams often depict the carbon cycle, showing how carbon moves among the atmosphere, biosphere, and oceans. In restoration ecology, managers might sketch how reconnecting wetlands to floodplains influences nutrient cycling, fish migration, and water quality. In all of these cases, the conceptual model serves as a foundation: it identifies key components, reveals possible feedbacks, and ensures that stakeholders have a common understanding before quantitative equations are developed. 4.3.2 Empirical Models Empirical models are constructed directly from observed data and aim to capture patterns without necessarily explaining the underlying processes. They are often built using regression, curve-fitting, or other statistical approaches. Strengths. Empirical models are quick to build when data are plentiful and can be highly accurate within the range of observed conditions. They are particularly useful for prediction tasks where explanation is less important. Limitations. Because they are not tied to underlying mechanisms, empirical models may fail when applied outside the range of the data (poor extrapolation). They also provide little insight into why a system behaves the way it does. Example. A regression model might link crop yield to rainfall amount, showing that higher rainfall generally leads to higher yields up to a point. While the model captures the correlation, it does not explain the underlying processes of soil moisture dynamics, plant physiology, or nutrient cycling. Empirical models are often a first step in modeling, helping reveal relationships that can later inspire more mechanistic or physically based models. 4.3.3 Mechanistic Models Mechanistic (or process-based) models attempt to represent the actual physical, chemical, or biological mechanisms driving a system. They are usually expressed in terms of equations that represent process rates or interactions. Strengths. Mechanistic models provide deeper explanatory power by focusing on why a system behaves in a particular way. Because they are based on processes, they can often be applied to new situations outside the range of existing data. Limitations. These models often require more assumptions, more data, and more expertise to build and calibrate. Example. A predatorprey model (LotkaVolterra equations) represents how predator consumption rates depend on prey abundance, and how prey populations decline or increase depending on predator pressure. Such models capture the interaction mechanisms rather than just observed correlations. Mechanistic models are particularly valuable when the goal is understanding causation, not just prediction. 4.3.4 Physically Based Models Physically based models are a subset of mechanistic models that rely explicitly on fundamental physical laws, such as conservation of mass, energy, and momentum. Strengths. Because they are grounded in universal principles, they are often considered more trustworthy and generalizable. They can be applied to different systems without retraining or refitting, as long as the physics remain the same. Limitations. They are often data-intensive and computationally demanding, which can make them challenging to apply in data-limited or resource-constrained contexts. Example. The advectiondispersion equation in hydrology models pollutant transport in groundwater. It explicitly represents the physical processes of advection (movement with flow), dispersion (spreading), and decay. Physically based models are essential in hydrology, climate science, and atmospheric modeling, where conservation principles govern large-scale dynamics. 4.3.5 Statistically Based Models Statistically based models focus on patterns and correlations in observed data rather than explicit mechanisms. They can include regression, generalized linear models, and modern statistical learning methods. Strengths. They are flexible, relatively quick to build, and effective at handling noisy or messy datasets. They are often useful when mechanisms are poorly understood but data are available. Limitations. These models can lack interpretability, may be limited to the conditions where data were collected, and can be prone to spurious correlations. Example. A multiple regression predicting air quality index (AQI) from temperature, wind speed, and traffic counts. This model may predict AQI well in urban areas with similar conditions, but may not generalize to other contexts or explain the underlying atmospheric chemistry. 4.3.6 Hybrid Models Hybrid models combine mechanistic or physically based components with statistical or empirical elements. Increasingly, they also incorporate machine learning to approximate processes that are too complex to model explicitly. Strengths. They balance explanatory depth with predictive accuracy, making them powerful tools for modern environmental modeling. They can use physics where mechanisms are well understood and statistics where processes are uncertain. Limitations. Hybrids can be complex to implement, requiring both strong process knowledge and advanced statistical or computational skills. Example. A climate model might use physical laws to simulate radiation balance while representing cloud formation statistically, since clouds are too complex to simulate explicitly at global scales. Hybrid approaches are especially useful for large, complex systems where no single modeling approach is sufficient. 4.3.7 Probability-Based Models Probability-based models incorporate randomness and uncertainty explicitly into the modeling process. Types. Stochastic models: allow variables to fluctuate randomly (e.g., rainfall arrivals modeled as a Poisson process). Monte Carlo simulations: use repeated random sampling to explore uncertainty in parameters or inputs. Markov models: describe transitions between discrete states with probabilities (e.g., land cover change from forest to agriculture). Strengths. These models are well-suited for risk analysis and decision-making under uncertainty, since they provide probabilities rather than deterministic outcomes. Limitations. They require careful specification of probability distributions, and results can be sensitive to those assumptions. Example. Wildfire spread models often use probabilistic elements to capture random ignition events, wind shifts, and fuel variability. While no one can predict the exact path of a fire, probability-based models estimate likely outcomes and risks. 4.3.8 Discrete vs Continuous Models The choice between discrete and continuous models depends on how processes unfold and how data are collected. Discrete models describe systems in stepwise updates, often expressed as difference equations. Example. Annual updates of a fish population with seasonal reproduction, where population counts are only recorded once a year. Continuous models describe change as a smooth process in time or space, often expressed as differential equations. Example. Logistic growth of a population or chemical reaction kinetics, where changes occur continuously over time. Comparison. Discrete models are natural when processes occur in pulses (e.g., seasonal breeding) or when data are only periodic. Continuous models are appropriate when change is ongoing and smooth (e.g., temperature variation through the day). In practice, modelers often switch between discrete and continuous formulations depending on data availability, computational needs, and the nature of the process being studied. 4.3.9 Summary These categoriesconceptual, empirical, mechanistic, physically based, statistically based, hybrid, probability-based, discrete, and continuousare not mutually exclusive. Many real-world models blend features from several categories. For example, a water quality model might use physically based equations for pollutant transport (continuous), include a statistical relationship for uncertain decay rates, and apply Monte Carlo simulations to capture uncertainty. The art of modeling lies in choosing the right combination of approaches that best fits the scientific or management question at hand. 4.4 Growth Models Growth models describe how quantities change over time. They are among the most widely used mathematical models in environmental science because they capture how populations expand, resources are consumed, or pollutants accumulate and decline. Each model makes assumptions about what drives growth, what limits it, and whether change is smooth or sudden. Below we introduce several canonical growth forms. 4.4.1 Linear Growth The simplest growth model is linear growth, where change occurs at a constant rate: \\[ y(t) = y_0 + rt \\] Here, \\(y_0\\) is the initial value and \\(r\\) is the constant rate of change. The relationship is straightforward: every unit of time adds the same amount. Environmental example. If a forest loses 1,000 hectares per year due to logging, the total deforested area increases linearly with time. Strengths and limitations. Linear growth is intuitive and easy to apply, but it rarely captures long-term dynamics because most systems eventually accelerate, decelerate, or fluctuate rather than changing at a constant rate. 4.4.2 Exponential Growth Exponential growth occurs when the rate of change is proportional to the current size: \\[ y(t) = y_0 e^{rt} \\] \\(r\\) is the intrinsic growth rate, and \\(y_0\\) is the initial value. Growth accelerates as the quantity increases, leading to the famous hockey-stick curve. Environmental example. An invasive species introduced to a new habitat may grow exponentially at first, since resources are abundant and predators are absent. Key property. Exponential growth has a doubling time given by: \\[ t_d = \\frac{\\ln 2}{r} \\] Strengths and limitations. Exponential models are powerful for short-term predictions but unrealistic over long periods, since no population or pollutant can grow without bound. 4.4.3 Logistic Growth To incorporate resource limits, the logistic growth model modifies exponential growth by adding a ceiling: \\[ y(t) = \\frac{K}{1 + A e^{-rt}}, \\quad A = \\frac{K - y_0}{y_0} \\] \\(K\\) is the carrying capacity, the maximum sustainable level. \\(r\\) is the intrinsic growth rate. \\(y_0\\) sets the initial condition. Environmental example. A fish population in a lake may grow quickly when small but will slow as competition for food intensifies, eventually stabilizing around a carrying capacity. Key features. Growth is fast at first, then slows as \\(y(t)\\) approaches \\(K\\). Produces an S-shaped (sigmoid) curve. Sensitive to both the growth rate \\(r\\) and the initial population \\(y_0\\). Strengths and limitations. Logistic models capture the idea of limits and feedbacks, making them more realistic than exponential growth. However, real systems may not have fixed carrying capacitiesthey can change seasonally or due to human interventions. 4.4.4 Decay Models Not all processes involve growth. Many environmental problems involve decay, where a quantity decreases over time, often following an exponential law: \\[ y(t) = y_0 e^{-\\lambda t} \\] \\(\\lambda\\) is the decay constant. \\(y_0\\) is the initial value at \\(t=0\\). Environmental examples. Pollutant concentrations decline after a cleanup effort. Radioactive isotopes lose mass at a fixed half-life. Key property. The half-life is given by: \\[ t_{1/2} = \\frac{\\ln 2}{\\lambda} \\] Strengths and limitations. Decay models are excellent first approximations but may oversimplify when multiple processes (e.g., mixing, resuspension, or nonlinear reactions) occur simultaneously. 4.4.5 Piecewise / Threshold Models Some systems behave differently depending on conditions. Piecewise or threshold models capture these shifts by switching between rules depending on whether a threshold is crossed. Example function: \\[ f(x) = \\begin{cases} 0 &amp; \\text{if } T \\leq 0^\\circ C \\\\ r(T) &amp; \\text{if } T &gt; 0^\\circ C \\end{cases} \\] Environmental example. Snowpack remains stable when air temperatures are below freezing but begins to melt rapidly once temperatures exceed 0 °C. Similarly, algal blooms may only occur when nutrient concentrations exceed a critical threshold. Strengths and limitations. Threshold models are powerful for representing abrupt changes, but they can be difficult to calibrate because identifying the exact threshold requires detailed data. 4.4.6 Putting It All Together Each of these growth models represents a different story of change: Linear growth assumes constant addition. Exponential growth assumes self-reinforcing acceleration. Logistic growth assumes feedback and limits. Decay assumes continual decline. Threshold models assume sudden shifts once a condition is met. In environmental modeling, these forms are often combined or extended. For instance, population models might include logistic growth with seasonal thresholds, while pollutant decay models might combine exponential decline with inflow terms. Choosing the right growth model is less about mathematical elegance and more about capturing the essential dynamics of the system under study. 4.5 Parameters in Growth Models Growth models are defined not just by their structure (linear, exponential, logistic, etc.) but also by their parameters. Parameters are the constants that govern how the system behaves. In growth models, the most common parameters include the intrinsic growth rate (\\(r\\)), the carrying capacity (\\(K\\)), and the decay constant (\\(\\lambda\\)). By adjusting these parameters, the same mathematical structure can represent very different ecological or environmental realities. 4.5.1 The Role of Parameters Growth rate (\\(r\\)) determines how quickly a population expands or a pollutant concentration changes. A higher \\(r\\) means faster growth or decline. Carrying capacity (\\(K\\)) represents the maximum sustainable size of a population given resource constraints. It can change with environmental conditions such as food availability, habitat size, or climate. Decay constant (\\(\\lambda\\)) dictates how quickly a substance or population decreases, often through chemical breakdown, radioactive decay, or mortality. Without parameters, models would be abstract formulas with no connection to the real world. Parameter values bring models to life by grounding them in observed systems. 4.5.2 Sensitivity Analysis A key step in working with models is asking: how sensitive is the outcome to the values of the parameters? If a small change in \\(r\\) leads to a large change in population size over time, then accurate estimation of \\(r\\) is crucial. If the outcome hardly changes when \\(K\\) is varied, then the model may be robust to uncertainty in that parameter. Sensitivity analysis helps us: 1. Identify which parameters matter most. 2. Focus data collection on the most influential parameters. 3. Understand the uncertainty in model predictions. Example. A fish population with a growth rate \\(r=0.2\\) per year reaches its carrying capacity in about 20 years. If \\(r\\) is actually 0.25, the same population may reach capacity in only 15 years. Such differences have direct management implications for harvest rules. 4.5.3 Visualization with Parameter Sweeps One effective way to explore parameter influence is through parameter sweepssystematically varying one parameter while holding others constant and plotting the results. Plotting logistic growth curves for several values of \\(r\\) shows how faster growth accelerates the time to reach carrying capacity. Plotting curves for different \\(K\\) values illustrates how the ceiling of growth changes. Parameter sweeps reveal families of curves and make the sensitivity of the system visually clear. Environmental example. Suppose two wetlands support frog populations with the same growth rate (\\(r\\)) but different carrying capacities (\\(K=500\\) vs. \\(K=1000\\)). A visualization would show both populations growing rapidly at first, but one leveling off sooner due to lower resource limits. 4.5.4 Comparing Competing Species Parameters also allow us to compare species or systems in meaningful ways. Example: Competing plants. Two plant species colonize a disturbed site. Species A has a higher growth rate (\\(r\\)) but a lower carrying capacity (\\(K\\)) due to limited resource efficiency. Species B has a slower growth rate but a higher carrying capacity. Which species dominates depends on the timescale of interest: in the short term, Species A may dominate, but in the long term, Species B may outlast it. Example: Invasive vs native fish. An invasive fish species may have a larger \\(r\\), allowing it to spread quickly, while a native species may be closer to carrying capacity. Understanding both parameters can guide whether intervention is urgent. 4.5.5 Summary Parameters are the levers of growth models. By adjusting \\(r\\), \\(K\\), or \\(\\lambda\\), the same mathematical structure can represent radically different ecological stories. Sensitivity analysis and parameter sweeps help identify which parameters drive system behavior, while comparative studies show how parameter differences can explain species competition and coexistence. In practice, estimating parameters from data is one of the most challenging but most important aspects of environmental modeling. 4.6 Fitting Models to Data So far we have introduced growth models as equations with parameters like \\(r\\), \\(K\\), or \\(\\lambda\\). But how do we actually determine the values of these parameters for a real-world system? This is where fitting models to data comes in. By comparing model predictions with observational data, we can estimate parameter values, assess how well the model represents reality, and quantify uncertainty. 4.6.1 From Observations to Parameters Environmental systems are usually monitored through field measurements, laboratory experiments, or remote sensing. These observations give us time series or spatial data that can be compared with model outputs. Example. Suppose we have a dataset of fish population counts from annual surveys of a lake. We can use these observations to estimate the growth rate \\(r\\) and carrying capacity \\(K\\) in a logistic model. Our first decision is which model suits this situation. Once we decide on a model form, we then need to determine the best parameter set. The goal is to select the right model and adjust model parameters so that the model trajectory matches the observed data as closely as possible. 4.6.2 Methods of Parameter Estimation Several approaches exist for estimating parameters from data. The choice depends on the model type, the data available, and the assumptions we are willing to make. Regression methods. Linear regression is used when the model can be written in a straight-line form. Nonlinear regression extends this to curves like logistic or exponential models. Least squares estimation. One of the most common approaches is to minimize the sum of squared errors (SSE) between observed values and model predictions: \\[ SSE = \\sum_{i=1}^n \\big(y_{\\text{obs},i} - y_{\\text{model},i}\\big)^2 \\] The parameter values that minimize the SSE are considered the best fit. Maximum likelihood estimation (MLE). A more general method that finds parameters most likely to produce the observed data under a given probability distribution. Often used when data are noisy or when errors do not follow a simple normal distribution. 4.6.3 Uncertainty and Error No parameter estimate is exact. Uncertainty arises from measurement error, sampling variability, and model assumptions. Good modeling practice requires quantifying and communicating this uncertainty. Confidence intervals around parameter estimates show the plausible range of values. Residual analysis (examining the differences between observed and predicted values) helps detect patterns that indicate model misfit. Cross-validation (fitting the model to part of the data and testing it on the rest) helps assess predictive power. In some cases, uncertainty in parameters can be propagated through the model using techniques such as Monte Carlo simulation, producing a range of possible outcomes rather than a single prediction. 4.6.4 Summary Fitting models to data is the bridge between theory and reality. Observations allow us to estimate parameters, while regression and least squares methods provide systematic ways to find the best fit. A logistic fit to population data is a classic example, but the same principles apply to pollutant decay, climate trends, or forest growth. Always remember that parameter estimates come with uncertainty, and acknowledging error is just as important as reporting the best values. "],["app-wk1.html", "Appendix A Project Week 1  The why and the what", " Appendix A Project Week 1  The why and the what \\(Y^n\\) Pick a system and ask why about some part you are interested Then ask a why again Keep asking why till you cant find the answer anymore Quick Demo Why does day length change?  Because of the seasons. As Earth orbits the Sun, sometimes your hemisphere is tilted toward the Sun (summer, longer days) and sometimes away (winter, shorter days). Why do we have seasons?  Because of the tilt of Earths axis. Earths axis is tilted about 23.5° relative to its orbit. This tilt changes how high the Sun appears in the sky and how long its path lasts each day. Why is Earth tilted?  Because of a giant collision in the early solar system. A Mars-sized body (often called Theia) likely struck Earth 4.5 billion years ago. This impact knocked Earth off a straight-up orientation and also produced the Moon. Why did that collision happen?  Because the early solar system was chaotic. When the Sun first formed, space around it was full of rocky planetesimals (early building blocks of planets). Their orbits overlapped, and gravity pulled them into frequent, violent collisions. Why was there a disk of planetesimals in the first place?  Because the solar system formed from a collapsing nebula. A cloud of gas and dust collapsed under gravity. As it collapsed, conservation of angular momentum caused the material to flatten into a spinning disk. Inside that disk, clumps grew into planetesimals and then planets. Why does the Earth spin in the first place?  Because of angular momentum inherited from the disk. The collapsing nebula was already rotating. As clumps of matter formed into planets, they retained that spin. Collisions and impacts modified Earths rotation rate and axis, but didnt stop the overall spin. Why did the nebula collapse?  Because of gravity and outside triggers. Dense regions of interstellar gas clouds naturally collapse under their own weight. This process may have been accelerated by shock waves from a nearby supernova explosion. Why was there a cloud of gas and dust?  Because of earlier generations of stars. Stars burn fuel and die. Supernovae scatter their contents into space, creating gas and dust clouds rich in heavy elements. Our solar system is made of this recycled stardust. Why do stars form and die?  Because of gravity and nuclear fusion. Gravity compresses gas until fusion ignites. Fusion powers stars until the fuel is gone, at which point they evolve into white dwarfs, neutron stars, or black holes. Why does nuclear fusion work?  Because of the fundamental forces of nature. Fusion is governed by gravity, electromagnetism, and the strong/weak nuclear forces. These make it possible for nuclei to fuse and release energy. Why do these fundamental forces exist, and why do they have the values they do?  That is an open question. Physics describes and measures these forces, but doesnt explain why they exist at all. This is the frontier where science meets philosophy and cosmology. \\(Y^{11}\\) Task 1 - Group of 5 Workshop your individual ideas with your group Spend 3 mins on each person (Ill set a timer) Ask ys Task 2 - 1 Line Description Take a couple minutes and try to write down - in one line - where your idea is at. This is not your final project topic - just a progress report Post this after class in the discussion opened for project ideas [P&amp;P] Comment on 3 posts - ask another specific why? [P&amp;P] Task 3 - Network Find the like minded people in the room Team up? Couple your models? Share thoughts "],["workbook-week-1-what-is-modeling.html", "Appendix B Workbook Week 1: What is Modeling?", " Appendix B Workbook Week 1: What is Modeling? Class Discussion Lets build a working definition of the central components of this course. In your groups see if you can define Coding Models/Modeling Simulation Systems Logic Syntax A key skill in being a modeler is the ability of abstraction Sketching Exercise A sketch is a visual model. Task: Draw a picture of a chair (1min) Share your picture with those around you What assumptions did you all make in your model Which sketch was right? Systems Thinking - what do we mean by this? Lets do my phd in 5 mins - plants in desert systems - lets think about this as a system. Pseudo code The art of writing good instructions Im a robot, and you want me to toast a bagel and put Vegemite on it. Write me the pseudo code to make this happen. This is what happens when you give bad instructions: This is whats possible with complete instructions: Group activity - Dice We want to know what the most likely total you would get from rolling two 6 sided die. Write some pseudo code to collect data to help you work this out. Guessing Game Write pseudo code that would count how many guesses you would take to find a number between 1 and 10. Needle in a Haystack In the Dan Brown novel Angels and Demons the Vatican is about to be blown up by a antimatter device. In the movie, the bad guys has a webcam on the device. Someone has the idea of systematically cutting power to the different sectors of the power grid to narrow down the location. They dismiss is because they work out there isnt enough time to cycle through all the sectors. But you took my class and actually make this idea work. Lets assume: We have 1,048,576 possible sectors. It takes 1hr for a sector to respond to a change Whats the longest time it would take to find the sector? What is the shortest time it would take to be sure you found the sector? Write some pseudo code "],["workbook-week-2-llms.html", "Appendix C Workbook Week 2: LLMs C.1 How to Build Complixity into a Problem C.2 LLMs and Modeling Support C.3 Friday Discussion - AI, Society &amp; the Environment", " Appendix C Workbook Week 2: LLMs C.1 How to Build Complixity into a Problem We briefly discussed the need to layer complexity when trying to model. Lets work through an example of that. Banksys Balloon Model Have you ever wondered what happens to a helium filled balloon that is released? What we will do is build a mathematical model of the balloon to help answer this question. What controls the height at which a the balloon will climb? \\[B(z) = f(\\] Abstraction What is the simplest form of the problem we could solve? What assumptions could we make to help us get started? Neutral Buoyancy Given the table below and the density information about helium. What height would the balloon get to? At sea-level conditions (about \\(T = 288\\,\\text{K}\\), \\(P = 101{,}325\\,\\text{Pa}\\)): Helium density: \\[ \\rho_{\\text{He}} \\approx 0.1785\\ \\text{kg/m}^3 \\] Evaluate and then add complexity Does this feel right? What assumptions did we make that might have been too simplistic? What math model could we apply to add complexity? Ideal Gas Law The ideal gas law relates the pressure, volume, temperature, and number of moles of a gas: \\[ PV = nRT \\] Definitions \\(P\\): Pressure of the gas (Pa or atm) \\(V\\): Volume of the gas (m³ or L) \\(n\\): Number of moles of gas (mol) \\(R\\): Ideal gas constant \\(8.314\\ \\text{J·mol}^{-1}\\text{·K}^{-1}\\) (SI units) \\(0.08206\\ \\text{L·atm·mol}^{-1}\\text{·K}^{-1}\\) (common chemistry units) \\(T\\): Absolute temperature (Kelvin, K) Notes - The equation assumes an ideal gas (no inter-molecular forces, particles take up negligible space). - Works well for helium and other light gases at normal temperatures and pressures. - Can be rearranged into useful forms, e.g. density: Flexible Balloon Lets let the volume of the balloon change - removing the rigid balloon requirement. \\[ PV = nRT \\] Rearranging for n: \\[ n = \\frac{PV}{RT} \\] We know n cant change as the balloon isnt leaking. So we can think of the balloon in two places \\[ n_{msl} = n_{top} \\] so plug the rest in \\[ \\frac{P_1V_1}{T_1}=\\frac{P_2V_2}{T_2} \\] Ask ourselves what changes based on out assumptions What is going to happen to the volume of the balloon as it climbs? What happens to the density of helium if the volume increases? \\[ \\rho = \\frac{M}{V} \\] Evaluate - Does this make sense? The next thing is to model where the balloon will land. This tool uses the near term forecast as well as the balloons parameters to determine the most likely trajectory. SondeHub Flight Predictor C.2 LLMs and Modeling Support C.2.1 Learning Objectives By the end of this week, students should be able to: Explain what large language models (LLMs) are and how they can support simulation and coding. Apply prompt engineering techniques to improve model development. Use LLMs to re-frame and clarify environmental modeling challenges. Critically evaluate when and how it is appropriate to use AI tools in science. Incorporate LLMs into workflows for reproducibility, documentation, and troubleshooting in R. C.2.2 Coding warmup Pseudo-code and r script activity Create a script that fits a line of best fit to the following string of 10 numbers 6,1,7,2,3,3,9,3,3,0 Create the flexibility in the code to fit a nth order polynomial of your choosing. Before you run build an expectation What do expect the graph to look like with n=1 n=5 n=9 n=12 What evaluation tools/outputs could you create so that you can test the output? Compare your expectations with your output Compare your outputs with the people around you C.2.3 What is a Large Language Model 1 min Discussion What is a LLM and how does it work? Class Discussion What are the dangers of highly parameterized model? Pros and cons of parameter counts? C.2.4 Pros and Cons of High-Parameter Models High-parameter (or high-complexity) models  like very high-degree polynomials, deep neural networks with many layers, or regression models with lots of predictors  have clear advantages and drawbacks. C.2.4.1  Pros Flexibility &amp; Expressiveness Can capture very complex relationships, including nonlinear patterns that simple models would miss. For example: a 9th-degree polynomial can fit 10 points exactly. Low Training Error With enough parameters, the model can drive error on the training set down to nearly zero. Useful if your goal is interpolation of the given data rather than generalization. Captures Subtle Structure Sometimes, especially with rich datasets, complexity helps reveal real underlying trends that simpler models would smooth over. C.2.4.2  Cons Overfitting The model fits noise as if it were signal. Predictions on new data are often unstable and inaccurate. Interpretability High-degree polynomials or models with many coefficients are hard to interpret or explain. Coefficients may be large, unstable, or counter-intuitive. Numerical Instability High-order polynomials can produce NAs or huge coefficients due to ill-conditioning. Small changes in input lead to large swings in output. Computational Cost More parameters = more computation, longer training, and sometimes risk of convergence issues. Generalization Risk High training accuracy doesnt guarantee real-world usefulness. Models may fail badly outside the range of training data. C.2.5 Parameters in Large Language Models (LLMs) Large Language Models (LLMs) are defined in part by the number of parameters they contain  the trainable weights in their neural networks. These parameters are like knobs the model adjusts during training to learn patterns in data. C.2.5.1  Parameters in Modern LLMs GPT-2 (2019)  ~1.5 billion parameters GPT-3 (2020)  175 billion parameters PaLM (Google, 2022)  540 billion parameters GPT-4 (2023)  parameter count not officially disclosed, but estimates suggest hundreds of billions to over a trillion GPT-4 Turbo (2023, OpenAI API)  optimized variant, size undisclosed, but still in the hundreds of billions range Anthropics Claude 3 (2024)  not public, but assumed similar scale (hundreds of billions) Gemini Ultra (Google DeepMind, 2024)  also undisclosed, estimated trillion-scale C.2.5.2  What Parameters Mean Each parameter is just a number (a weight) that influences how input tokens get transformed through the layers of the neural net. More parameters = more capacity to model complex relationships, but also: Requires more data to train Much more compute (training GPT-3 took thousands of GPUs for weeks) Can increase risk of overfitting if not carefully regularized C.2.5.3  Trend in LLM Growth 20182020  billions of parameters 20212023  hundreds of billions 2024 onward  trillion+ parameter models (but with a shift toward efficiency  smaller models trained better) Contextualizing these large numbers 1 million seconds &gt; 11.6 days 1 billion seconds &gt; 31.7 years (~1.5 of your lifetimes) 1 trillion seconds &gt; 31,700 years (~1,500 your lifetimes) C.2.5.4  Table: LLMs and Parameter Counts Model Year Parameters (approx.) Notes GPT-2 2019 1.5B First widely known OpenAI LLM GPT-3 2020 175B Major leap in scale PaLM (Google) 2022 540B Pathways Language Model GPT-4 2023 100B1T (est.) Exact number undisclosed GPT-4 Turbo 2023 100B+ (est.) Optimized API variant Claude 3 (Anthropic) 2024 100B+ (est.) Scale similar to GPT-4 Gemini Ultra (Google) 2024 1T+ (est.) Trillion-scale model  Summary: Modern LLMs like GPT-4, Claude 3, or Gemini are likely running in the hundreds of billions to trillions of parameters range. C.2.6 Capabilities and Limits of LLMs Discussion: What are the Capabilities and Limits of LLMs Reflection Prompt Capabilities and Limits of LLMs  Capabilities of LLMs Generate readable text in many styles Scientific summaries Conversational explanations Adapt tone for peers, policymakers, or the public Produce and troubleshoot code Works across multiple languages (R, Python, MATLAB) Draft starter scripts, find syntax errors, explore alternatives Summarization tools Condense long articles, datasets, or equations Highlight key insights and trends Translate technical content into plain language Make specialized knowledge understandable to non-experts Support communication of environmental science to diverse audiences  Limits of LLMs Hallucination Can produce text that sounds plausible but is factually wrong Bias in training data May reproduce stereotypes or skew perspectives Lack of true reasoning/understanding Predicts patterns statistically, not by scientific comprehension Explanations may oversimplify or omit key assumptions Reproducibility challenges Same prompt can yield different outputs Hard to fully standardize in scientific workflows Which of the capabilities described here could have supported your work? Which limitations would you need to watch out for? How might you balance the efficiency of using an LLM with the need for accuracy and scientific rigor? C.2.7 LLMs in environmental modeling workflows Activity: Explain a Complex Model with Stepwise Prompting Google Doc For Group Notes Well use stepwise (chain-of-thoughtstyle) prompting to unpack a very complex partial differential equation into clear, audience-appropriate language without asking the AI to reveal its private reasoning. The goal is to force a structured, term-by-term explanation and surface assumptions. Note: we are purposefully using a complex example here so that we can really see the value and dangers of utilizing a LLM for environmental modeling. Model The AdvectionDiffusion (or Dispersion) Equation for pollutant transport in a river: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] - \\(C\\): concentration at position \\(x\\) and time \\(t\\) - \\(D\\): diffusion coefficient (mixing) - \\(v\\): flow velocity (downstream transport) - \\(k\\): decay rate (removal) Step 1  Your Own Explanation Write a plain-language explanation for a non-scientist audience (e.g., a community group). If you have no idea whats going on - take a guess. Go term by term and see if you can decipher whats going on. Step 2  Baseline AI Explanation Ask an LLM for a plain-language explanation. Save the response. Baseline prompt: Explain the equation below in plain language for a non-scientist audience. \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Keep it to 68 sentences. Take a second here and compare your result with those at your table? Are thy identical? Step 3  Stepwise Prompting (Structured Sections) Now force structure so the AI unpacks complexity term-by-term and surfaces assumptions. Stepwise prompt template (copy-paste) Explain the equation below using labeled sections. Do not show your internal reasoning; present only your final explanation. Sections (use headings): 1) Term-by-term meaning  explain each term in one sentence. 2) Physical interpretation  connect each term to a river process with a brief analogy. 3) Assumptions  list key modeling assumptions (e.g., dimensionality, parameter constancy, uniform mixing). 4) Units &amp; parameters  specify typical units for \\(C, D, v, k\\). 5) Edge cases  describe what happens if \\(D=0\\), \\(v=0\\), or \\(k=0\\). 6) Plain-language summary  3 sentences for a public audience. Equation: \\[ \\frac{\\partial C}{\\partial t} = D \\frac{\\partial^2 C}{\\partial x^2} - v \\frac{\\partial C}{\\partial x} - kC \\] Step 4  Compare &amp; Critique Clarity: Which version (baseline vs. stepwise) is clearer and why? Completeness: Did the stepwise version expose assumptions or units the baseline missed? Accuracy: Note any incorrect claims or overconfidence. Most importantly - which version did you learn something from? Step 5  Constraint Refinement Re-prompt with tighter constraints to match a specific audience. Audience-tuning examples Policy brief style (150 words, 8th-grade reading level). Technical appendix style (include parameter ranges and citations placeholder). Infographic caption style (90 words, 3 bullets + 1 summary sentence). How did it do translating complex ideas? Extension (optional) Ask the AI to propose a simple diagram description (no image needed): axes, arrows for diffusion/advection, and a decay curve. Use this as a storyboard for a figure you might create later. C.3 Friday Discussion - AI, Society &amp; the Environment Students will rotate through 6 stations, discussing and writing responses to each prompt. Station 1  Environmental Applications Prompt: How could LLMs help in environmental science (climate modeling, biodiversity tracking, sustainability research)? Use Description / Findings Role of AI/LLMs Citation Automated ecological data extraction LLMs used to parse ecological literature 50× faster than humans, with &gt; 90% accuracy for categorical data. Text mining &amp; knowledge extraction Nature (2024) Biodiversity commitments vs renewables tradeoffs LLM + GIS framework to compare biodiversity promises vs real-world impacts in renewable energy projects. Synthesizing documents with spatial data Purdue (2024) Policy &amp; governance support LLM-based chatbot assisting with biodiversity treaty policy interpretation and decision-making. Policy Q&amp;A, summarization &amp; interpretation Nature (2025) Land-use / biodiversity predictions Cambridge Terra AI tool predicts biodiversity impacts of land-use, supporting policy tradeoffs. Modeling + scenario analysis Cambridge (2025) Biodiversity &amp; conservation AI helps with species detection, habitat mapping, and biodiversity understanding. Pattern recognition (images, acoustics, mapping) OSU Imageomics (2025) Risks &amp; benefits review Review article on how LLMs can support environmental participation but also bring risks. Framing debates, generating text &amp; synthesis ACS EST (2023) Station 2  Risks in Science &amp; Policy Prompt: What are the risks if AI models mislead scientists, policymakers, or the public about environmental issues? Station 3  Environmental Footprint of AI Prompt: LLMs require huge amounts of energy and water to run. Is their environmental cost justified by their benefits? Why or why not? Water Use Sources: https://watercalculator.org/; Lawrence Berkeley National Labs Scenario Liters per person per year People needed to reach 1B liters/year Direct household use ~114,000 L ~8,800 people Full water footprint (direct + virtual) ~2,842,000 L ~350 people Station 4  Learning &amp; Academic Integrity Prompt: How should students and researchers use AI responsibly in their work? Wheres the line between help and cheating? Tokens processed - why the drop in the June? Station 5  Equity &amp; Bias Prompt: Who risks being excluded? How might biases in LLMs affect society and science? Disparity / Exclusion / Bias How / Why Solution? Station 6  Future of Work &amp; Society Prompt: How might AI change jobs, communication, and decision-making in the next 10 years? What should never be automated? "],["tutorial-getting-started-with-rstudio.html", "Appendix D Tutorial: Getting Started with RStudio D.1 1. What is RStudio? D.2 2. The RStudio Interface D.3 3. Running Code D.4 4. Projects in RStudio D.5 5. Working with Packages D.6 6. Writing and Saving Scripts D.7 7. Plotting Example", " Appendix D Tutorial: Getting Started with RStudio D.1 1. What is RStudio? R is a programming language for statistics, data analysis, and visualization. RStudio is an integrated development environment (IDE) that makes R easier to use with a friendly interface. D.2 2. The RStudio Interface When you open RStudio, youll usually see four main panes: Source Pane (Top-Left) Where you write and edit R scripts (.R), RMarkdown (.Rmd), or notebooks. You can run code line by line or in chunks. Console (Bottom-Left) Where R actually runs the code. You can type commands directly here for quick tests. Environment/History (Top-Right) Environment: Shows the objects (data, variables, functions) youve created. History: Keeps track of commands youve previously run. Files/Plots/Packages/Help/Viewer (Bottom-Right) Files: Navigate your project folder. Plots: Displays graphs you generate. Packages: Manage installed R packages. Help: Documentation for R functions. Viewer: Preview HTML outputs (e.g., from RMarkdown). D.3 3. Running Code Type directly into the Console and hit Enter. Or, write code in the Source Pane and: Run a single line: Ctrl + Enter (Windows) or Cmd + Enter (Mac). Run a whole script: Source button or Ctrl + Shift + Enter. D.4 4. Projects in RStudio Create a Project to keep related files together. File  New Project  New Directory (or link to an existing folder). Projects make it easier to manage code, datasets, and outputs without breaking file paths. D.5 5. Working with Packages Packages are collections of R functions, data, and documentation bundled together to extend the capabilities of base R. Think of them like apps you install on your phone  R comes with some built-in tools, but packages let you do much more specialized tasks. Why use packages? Packages provide extra functionality for tasks like data visualization, statistical modeling, spatial analysis, or machine learning. Where do they come from? Most packages are shared on CRAN (the Comprehensive R Archive Network), but you can also install from GitHub or other repositories. How do you use them? Install once per computer install.packages(&quot;ggplot2&quot;) Load every session (so R knows to use it) library(ggplot2) Examples of popular packages: ggplot2  advanced graphics and plots dplyr  data wrangling and manipulation tidyr  reshaping datasets readr  reading CSV and text files shiny  building interactive web apps in R  Key idea: Packages expand what R can do. Installing adds them to your computer, loading makes them available in your current session. D.6 6. Writing and Saving Scripts When you work in RStudio, youll often want to save your code so you can reuse it later, share it with others, or keep a record of what you did. This is where scripts come in. D.6.1 R Scripts (.R files) An R script is a plain text file that contains R code. You can write multiple lines of code and run them whenever you want, instead of typing directly into the Console. To create one: Go to File  New File  R Script (or use Ctrl + Shift + N / Cmd + Shift + N on Mac). To save: Use File  Save As... and give your file a name ending in .R. D.6.2 RMarkdown (.Rmd files) An RMarkdown file combines code, text, and output in one document. Useful for reports, homework assignments, or reproducible research. To create one: File  New File  RMarkdown You can include code chunks (inside triple backticks {r}) along with explanations in plain English. Output can be HTML, PDF, or Word documents. D.7 7. Plotting Example R makes it easy to create plots and visualize data. Plots always appear in the Plots tab (bottom-right pane in RStudio). D.7.1 Example 1: Simple Scatter Plot You can create your own vectors and plot them. # Create data x &lt;- 1:10 y &lt;- x^2 # Scatter plot plot(x, y, main = &quot;Simple Plot&quot;, xlab = &quot;x&quot;, ylab = &quot;y^2&quot;) This will generate a basic scatter plot of numbers 110 against their squares. D.7.2 Example 2: Using a Built-In Dataset (cars) R comes with many built-in datasets. The cars dataset contains two columns: speed  speed of cars (in mph) dist  stopping distances (in feet) We can quickly make a scatter plot to explore the relationship. # Look at the first rows of the dataset head(cars) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 7 22 ## 5 8 16 ## 6 9 10 # Create a scatter plot plot(cars$speed, cars$dist, main = &quot;Stopping Distance vs Speed&quot;, xlab = &quot;Speed (mph)&quot;, ylab = &quot;Stopping Distance (ft)&quot;, col = &quot;blue&quot;, pch = 19) col = blue makes the points blue. pch = 19 makes the points solid circles. D.7.3 Example 3: Adding a Trend Line You can add extra layers to your plots. For instance, lets fit a simple linear model and add the regression line to the cars plot. # Fit a linear model model &lt;- lm(dist ~ speed, data = cars) # Plot again plot(cars$speed, cars$dist, main = &quot;Stopping Distance vs Speed with Trend Line&quot;, xlab = &quot;Speed (mph)&quot;, ylab = &quot;Stopping Distance (ft)&quot;, col = &quot;darkgreen&quot;, pch = 16) # Add the fitted line abline(model, col = &quot;red&quot;, lwd = 2) D.7.3.1 ggplot2 Version The ggplot2 package provides more control and produces publication-quality graphics. # Load ggplot2 library(ggplot2) # Create scatter plot with regression line ggplot(cars, aes(x = speed, y = dist)) + geom_point(color = &quot;darkgreen&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, color = &quot;red&quot;, se = FALSE) + labs( title = &quot;Stopping Distance vs Speed with Trend Line&quot;, x = &quot;Speed (mph)&quot;, y = &quot;Stopping Distance (ft)&quot; ) ## `geom_smooth()` using formula = &#39;y ~ x&#39;  Using base R, you get quick and simple plots.  Using ggplot2, you get more flexible, customizable, and professional-looking plots. "]]
